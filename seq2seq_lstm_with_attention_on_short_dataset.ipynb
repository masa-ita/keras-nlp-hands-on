{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "seq2seq_with_attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QetvaJ27Tb6y",
        "outputId": "ed288bf3-bcce-462b-dd13-a7a80ca2cc71"
      },
      "source": [
        "!pip install japanize_matplotlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting japanize_matplotlib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/85/08a4b7fe8987582d99d9bb7ad0ff1ec75439359a7f9690a0dbf2dbf98b15/japanize-matplotlib-1.1.3.tar.gz (4.1MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1MB 31.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from japanize_matplotlib) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (1.19.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->japanize_matplotlib) (1.15.0)\n",
            "Building wheels for collected packages: japanize-matplotlib\n",
            "  Building wheel for japanize-matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for japanize-matplotlib: filename=japanize_matplotlib-1.1.3-cp36-none-any.whl size=4120276 sha256=9956400cee24f7e8bf4d0b86f1a7f63b80b1bdb590ea8f4a2224505216c8f84d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/d9/a2/f907d50b32a2d2008ce5d691d30fb6569c2c93eefcfde55202\n",
            "Successfully built japanize-matplotlib\n",
            "Installing collected packages: japanize-matplotlib\n",
            "Successfully installed japanize-matplotlib-1.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M-eDSyL-8E7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b653d26-6168-41bf-f55c-6f5a2181e759"
      },
      "source": [
        "from tensorflow.keras.utils import get_file\n",
        "\n",
        "url = 'https://github.com/odashi/small_parallel_enja/archive/master.zip'\n",
        "\n",
        "zip_file_path = get_file('small_parallel_enja.zip', url, cache_subdir='small_parallel_enja', extract=True) "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/odashi/small_parallel_enja/archive/master.zip\n",
            "2416640/Unknown - 1s 0us/step"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsrpAmZ1BVFF",
        "outputId": "7686fe1c-60c9-4d2b-d073-3550ee5303a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "data_dir = os.path.join(os.path.dirname(zip_file_path), 'small_parallel_enja-master')\n",
        "!ls -l $data_dir"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 9076\n",
            "-rw-r--r-- 1 root root   17054 Feb  8 06:37 dev.en\n",
            "-rw-r--r-- 1 root root   27781 Feb  8 06:37 dev.ja\n",
            "-rw-r--r-- 1 root root    1946 Feb  8 06:37 README.md\n",
            "-rw-r--r-- 1 root root   17301 Feb  8 06:37 test.en\n",
            "-rw-r--r-- 1 root root   27793 Feb  8 06:37 test.ja\n",
            "-rw-r--r-- 1 root root 1701356 Feb  8 06:37 train.en\n",
            "-rw-r--r-- 1 root root  339768 Feb  8 06:37 train.en.000\n",
            "-rw-r--r-- 1 root root  340186 Feb  8 06:37 train.en.001\n",
            "-rw-r--r-- 1 root root  341174 Feb  8 06:37 train.en.002\n",
            "-rw-r--r-- 1 root root  339953 Feb  8 06:37 train.en.003\n",
            "-rw-r--r-- 1 root root  340275 Feb  8 06:37 train.en.004\n",
            "-rw-r--r-- 1 root root   30025 Feb  8 06:37 train.en.vocab.4k\n",
            "-rw-r--r-- 1 root root   51162 Feb  8 06:37 train.en.vocab.all\n",
            "-rw-r--r-- 1 root root 2784447 Feb  8 06:37 train.ja\n",
            "-rw-r--r-- 1 root root  556444 Feb  8 06:37 train.ja.000\n",
            "-rw-r--r-- 1 root root  555732 Feb  8 06:37 train.ja.001\n",
            "-rw-r--r-- 1 root root  557218 Feb  8 06:37 train.ja.002\n",
            "-rw-r--r-- 1 root root  557538 Feb  8 06:37 train.ja.003\n",
            "-rw-r--r-- 1 root root  557515 Feb  8 06:37 train.ja.004\n",
            "-rw-r--r-- 1 root root   31009 Feb  8 06:37 train.ja.vocab.4k\n",
            "-rw-r--r-- 1 root root   73669 Feb  8 06:37 train.ja.vocab.all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8meT2QYBrTN"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def load_data(path):\n",
        "      tokenizer = Tokenizer(filters='')\n",
        "      texts = []\n",
        "      for line in open(path, 'r'):\n",
        "          texts.append('<start> ' + line.strip() + ' <end>')\n",
        "    \n",
        "      tokenizer.fit_on_texts(texts)\n",
        "\n",
        "      return tokenizer.texts_to_sequences(texts), tokenizer\n",
        "\n",
        "en, inp_lang = load_data(os.path.join(data_dir, 'train.en'))\n",
        "ja, targ_lang = load_data(os.path.join(data_dir, 'train.ja'))\n",
        "\n",
        "vocab_inp_size = len(inp_lang.word_index) + 1\n",
        "vocab_tar_size = len(targ_lang.word_index) + 1\n",
        "\n",
        "train_en, test_en, train_ja, test_ja = train_test_split(en, ja, test_size=0.1, random_state=36)\n",
        "\n",
        "input_tensor_train = pad_sequences(train_en, padding='post')\n",
        "target_tensor_train = pad_sequences(train_ja, padding='post')\n",
        "input_tensor_val = pad_sequences(test_en, padding='post')\n",
        "target_tensor_val = pad_sequences(test_ja, padding='post')\n",
        "\n",
        "max_length_inp = len(input_tensor_train[0])\n",
        "max_length_targ = len(target_tensor_train[0])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfxSreRrXvw4"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "    for t in tensor:\n",
        "        if t!=0:\n",
        "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBMUz4Q9Xxe7",
        "outputId": "a55b4c0b-15ec-4286-95ec-8b86b6cf9095"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "5 ----> i\n",
            "512 ----> walked\n",
            "12 ----> in\n",
            "4 ----> the\n",
            "2801 ----> woods\n",
            "51 ----> by\n",
            "410 ----> myself\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "17 ----> 私\n",
            "4 ----> は\n",
            "265 ----> 一人\n",
            "11 ----> で\n",
            "1571 ----> 森\n",
            "8 ----> を\n",
            "198 ----> 歩\n",
            "5 ----> い\n",
            "7 ----> た\n",
            "3 ----> 。\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDYSOGLzYbP8"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train) // BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkZvi19gYp03",
        "outputId": "6597cf1f-4b32-43fe-8656-ad90869c5812"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 18]), TensorShape([64, 18]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYHYgc4hYwly"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units,):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.LSTM(self.enc_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, *states = self.lstm(x)\n",
        "        return output, states"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5fs_ECmZP8N",
        "outputId": "2fdf31aa-ce5e-410e-8858-8d570b38e4d2"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units,)\n",
        "\n",
        "# サンプル入力\n",
        "sample_output, sample_hidden = encoder(example_input_batch)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden[0].shape))\n",
        "print ('Encoder Carry state shape: (batch size, units) {}'.format(sample_hidden[1].shape))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 18, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n",
            "Encoder Carry state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRy4fGRXZU9P"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        # hidden shape == (batch_size, hidden size)\n",
        "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # スコアを計算するためにこのように加算を実行する\n",
        "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # スコアを self.V に適用するために最後の軸は 1 となる\n",
        "        # self.V に適用する前のテンソルの shape は  (batch_size, max_length, units)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "                      self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "        # attention_weights の shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "        # context_vector の合計後の shape == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaX0KziyZoN5",
        "outputId": "449cc94d-adf5-4925-ef71-7a6e61d6a99c"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden[0], sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 18, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzuNjW0lZs1y"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = tf.keras.layers.LSTM(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        \n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        # アテンションのため\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # enc_output の shape == (batch_size, max_length, hidden_size)\n",
        "        context_vector, attention_weights = self.attention(hidden[0], enc_output)\n",
        "\n",
        "        # 埋め込み層を通過したあとの x の shape  == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # 結合後の x の shape == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "        # 結合したベクトルを LSTM 層に渡す\n",
        "        output, *states = self.lstm(x, initial_state=hidden)\n",
        "\n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "        # output shape == (batch_size, vocab)\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, states, attention_weights"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP8fSgqDZ9Ci",
        "outputId": "e52f7d4e-6ce2-40a3-fc31-3961e2c8f9ae"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 8777)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOmW4oGQaBuJ"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "                             from_logits=True, reduction='none')\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1xOnT6oaOCY"
      },
      "source": [
        "import os\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaknH7tgaTEt"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp)\n",
        "\n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        # Teacher Forcing - 正解値を次の入力として供給\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            # passing enc_output to the decoder\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "            # Teacher Forcing を使用\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bNwa8eCa0Ru",
        "outputId": "0856736a-95c4-4171-f910-401760d9e6e5"
      },
      "source": [
        "import time\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "              print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                     batch,\n",
        "                                                     batch_loss.numpy()))\n",
        "    # 2 エポックごとにモデル（のチェックポイント）を保存\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 6.5420\n",
            "Epoch 1 Batch 100 Loss 3.3040\n",
            "Epoch 1 Batch 200 Loss 2.7456\n",
            "Epoch 1 Batch 300 Loss 2.3325\n",
            "Epoch 1 Batch 400 Loss 2.2212\n",
            "Epoch 1 Batch 500 Loss 2.1346\n",
            "Epoch 1 Batch 600 Loss 2.0940\n",
            "Epoch 1 Batch 700 Loss 1.9402\n",
            "Epoch 1 Loss 2.5035\n",
            "Time taken for 1 epoch 136.60128211975098 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.0291\n",
            "Epoch 2 Batch 100 Loss 1.7774\n",
            "Epoch 2 Batch 200 Loss 1.8224\n",
            "Epoch 2 Batch 300 Loss 1.7631\n",
            "Epoch 2 Batch 400 Loss 1.6353\n",
            "Epoch 2 Batch 500 Loss 1.5951\n",
            "Epoch 2 Batch 600 Loss 1.5978\n",
            "Epoch 2 Batch 700 Loss 1.6126\n",
            "Epoch 2 Loss 1.7294\n",
            "Time taken for 1 epoch 119.29598116874695 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.5453\n",
            "Epoch 3 Batch 100 Loss 1.4705\n",
            "Epoch 3 Batch 200 Loss 1.4599\n",
            "Epoch 3 Batch 300 Loss 1.4624\n",
            "Epoch 3 Batch 400 Loss 1.4513\n",
            "Epoch 3 Batch 500 Loss 1.3117\n",
            "Epoch 3 Batch 600 Loss 1.4043\n",
            "Epoch 3 Batch 700 Loss 1.4954\n",
            "Epoch 3 Loss 1.4429\n",
            "Time taken for 1 epoch 118.2924337387085 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.3375\n",
            "Epoch 4 Batch 100 Loss 1.3268\n",
            "Epoch 4 Batch 200 Loss 1.2874\n",
            "Epoch 4 Batch 300 Loss 1.2111\n",
            "Epoch 4 Batch 400 Loss 1.2304\n",
            "Epoch 4 Batch 500 Loss 1.2338\n",
            "Epoch 4 Batch 600 Loss 1.1073\n",
            "Epoch 4 Batch 700 Loss 1.1631\n",
            "Epoch 4 Loss 1.2141\n",
            "Time taken for 1 epoch 119.41258215904236 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.0663\n",
            "Epoch 5 Batch 100 Loss 1.0437\n",
            "Epoch 5 Batch 200 Loss 1.0514\n",
            "Epoch 5 Batch 300 Loss 0.9701\n",
            "Epoch 5 Batch 400 Loss 0.9067\n",
            "Epoch 5 Batch 500 Loss 1.0766\n",
            "Epoch 5 Batch 600 Loss 0.9127\n",
            "Epoch 5 Batch 700 Loss 0.9474\n",
            "Epoch 5 Loss 1.0140\n",
            "Time taken for 1 epoch 118.44847059249878 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.8762\n",
            "Epoch 6 Batch 100 Loss 0.8225\n",
            "Epoch 6 Batch 200 Loss 0.8942\n",
            "Epoch 6 Batch 300 Loss 0.7938\n",
            "Epoch 6 Batch 400 Loss 0.8433\n",
            "Epoch 6 Batch 500 Loss 0.7945\n",
            "Epoch 6 Batch 600 Loss 0.8106\n",
            "Epoch 6 Batch 700 Loss 0.8718\n",
            "Epoch 6 Loss 0.8431\n",
            "Time taken for 1 epoch 119.22880005836487 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.6007\n",
            "Epoch 7 Batch 100 Loss 0.6419\n",
            "Epoch 7 Batch 200 Loss 0.6766\n",
            "Epoch 7 Batch 300 Loss 0.7535\n",
            "Epoch 7 Batch 400 Loss 0.7818\n",
            "Epoch 7 Batch 500 Loss 0.6883\n",
            "Epoch 7 Batch 600 Loss 0.6985\n",
            "Epoch 7 Batch 700 Loss 0.6349\n",
            "Epoch 7 Loss 0.6941\n",
            "Time taken for 1 epoch 118.52391052246094 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.5586\n",
            "Epoch 8 Batch 100 Loss 0.5612\n",
            "Epoch 8 Batch 200 Loss 0.5924\n",
            "Epoch 8 Batch 300 Loss 0.5185\n",
            "Epoch 8 Batch 400 Loss 0.5242\n",
            "Epoch 8 Batch 500 Loss 0.6227\n",
            "Epoch 8 Batch 600 Loss 0.6122\n",
            "Epoch 8 Batch 700 Loss 0.5624\n",
            "Epoch 8 Loss 0.5640\n",
            "Time taken for 1 epoch 119.21343755722046 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.4032\n",
            "Epoch 9 Batch 100 Loss 0.4043\n",
            "Epoch 9 Batch 200 Loss 0.4153\n",
            "Epoch 9 Batch 300 Loss 0.4703\n",
            "Epoch 9 Batch 400 Loss 0.4630\n",
            "Epoch 9 Batch 500 Loss 0.4711\n",
            "Epoch 9 Batch 600 Loss 0.4782\n",
            "Epoch 9 Batch 700 Loss 0.5179\n",
            "Epoch 9 Loss 0.4492\n",
            "Time taken for 1 epoch 118.42195582389832 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.3048\n",
            "Epoch 10 Batch 100 Loss 0.3346\n",
            "Epoch 10 Batch 200 Loss 0.3164\n",
            "Epoch 10 Batch 300 Loss 0.3357\n",
            "Epoch 10 Batch 400 Loss 0.3993\n",
            "Epoch 10 Batch 500 Loss 0.3510\n",
            "Epoch 10 Batch 600 Loss 0.3920\n",
            "Epoch 10 Batch 700 Loss 0.3901\n",
            "Epoch 10 Loss 0.3474\n",
            "Time taken for 1 epoch 119.3542218208313 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.2113\n",
            "Epoch 11 Batch 100 Loss 0.2332\n",
            "Epoch 11 Batch 200 Loss 0.2580\n",
            "Epoch 11 Batch 300 Loss 0.2862\n",
            "Epoch 11 Batch 400 Loss 0.2592\n",
            "Epoch 11 Batch 500 Loss 0.2954\n",
            "Epoch 11 Batch 600 Loss 0.2983\n",
            "Epoch 11 Batch 700 Loss 0.2818\n",
            "Epoch 11 Loss 0.2641\n",
            "Time taken for 1 epoch 118.44520044326782 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.1778\n",
            "Epoch 12 Batch 100 Loss 0.1895\n",
            "Epoch 12 Batch 200 Loss 0.1664\n",
            "Epoch 12 Batch 300 Loss 0.1976\n",
            "Epoch 12 Batch 400 Loss 0.1879\n",
            "Epoch 12 Batch 500 Loss 0.2425\n",
            "Epoch 12 Batch 600 Loss 0.1940\n",
            "Epoch 12 Batch 700 Loss 0.2093\n",
            "Epoch 12 Loss 0.1965\n",
            "Time taken for 1 epoch 119.25399398803711 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.1283\n",
            "Epoch 13 Batch 100 Loss 0.1233\n",
            "Epoch 13 Batch 200 Loss 0.1122\n",
            "Epoch 13 Batch 300 Loss 0.1439\n",
            "Epoch 13 Batch 400 Loss 0.1357\n",
            "Epoch 13 Batch 500 Loss 0.1455\n",
            "Epoch 13 Batch 600 Loss 0.1565\n",
            "Epoch 13 Batch 700 Loss 0.2149\n",
            "Epoch 13 Loss 0.1474\n",
            "Time taken for 1 epoch 118.28710436820984 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.1082\n",
            "Epoch 14 Batch 100 Loss 0.1003\n",
            "Epoch 14 Batch 200 Loss 0.0942\n",
            "Epoch 14 Batch 300 Loss 0.0874\n",
            "Epoch 14 Batch 400 Loss 0.1009\n",
            "Epoch 14 Batch 500 Loss 0.0959\n",
            "Epoch 14 Batch 600 Loss 0.1111\n",
            "Epoch 14 Batch 700 Loss 0.1345\n",
            "Epoch 14 Loss 0.1137\n",
            "Time taken for 1 epoch 119.0753104686737 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.0975\n",
            "Epoch 15 Batch 100 Loss 0.0844\n",
            "Epoch 15 Batch 200 Loss 0.0659\n",
            "Epoch 15 Batch 300 Loss 0.0846\n",
            "Epoch 15 Batch 400 Loss 0.1146\n",
            "Epoch 15 Batch 500 Loss 0.1088\n",
            "Epoch 15 Batch 600 Loss 0.0947\n",
            "Epoch 15 Batch 700 Loss 0.1136\n",
            "Epoch 15 Loss 0.0915\n",
            "Time taken for 1 epoch 118.3522481918335 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.0681\n",
            "Epoch 16 Batch 100 Loss 0.0741\n",
            "Epoch 16 Batch 200 Loss 0.0825\n",
            "Epoch 16 Batch 300 Loss 0.0655\n",
            "Epoch 16 Batch 400 Loss 0.0796\n",
            "Epoch 16 Batch 500 Loss 0.0920\n",
            "Epoch 16 Batch 600 Loss 0.0801\n",
            "Epoch 16 Batch 700 Loss 0.1072\n",
            "Epoch 16 Loss 0.0787\n",
            "Time taken for 1 epoch 119.16292953491211 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.0579\n",
            "Epoch 17 Batch 100 Loss 0.0533\n",
            "Epoch 17 Batch 200 Loss 0.0435\n",
            "Epoch 17 Batch 300 Loss 0.0725\n",
            "Epoch 17 Batch 400 Loss 0.0831\n",
            "Epoch 17 Batch 500 Loss 0.0924\n",
            "Epoch 17 Batch 600 Loss 0.0844\n",
            "Epoch 17 Batch 700 Loss 0.1133\n",
            "Epoch 17 Loss 0.0727\n",
            "Time taken for 1 epoch 118.7878930568695 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.0727\n",
            "Epoch 18 Batch 100 Loss 0.0565\n",
            "Epoch 18 Batch 200 Loss 0.0559\n",
            "Epoch 18 Batch 300 Loss 0.0592\n",
            "Epoch 18 Batch 400 Loss 0.0689\n",
            "Epoch 18 Batch 500 Loss 0.0625\n",
            "Epoch 18 Batch 600 Loss 0.0831\n",
            "Epoch 18 Batch 700 Loss 0.0943\n",
            "Epoch 18 Loss 0.0663\n",
            "Time taken for 1 epoch 119.48980402946472 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.0667\n",
            "Epoch 19 Batch 100 Loss 0.0640\n",
            "Epoch 19 Batch 200 Loss 0.0553\n",
            "Epoch 19 Batch 300 Loss 0.0522\n",
            "Epoch 19 Batch 400 Loss 0.0617\n",
            "Epoch 19 Batch 500 Loss 0.0710\n",
            "Epoch 19 Batch 600 Loss 0.0894\n",
            "Epoch 19 Batch 700 Loss 0.0976\n",
            "Epoch 19 Loss 0.0641\n",
            "Time taken for 1 epoch 118.44379091262817 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.0471\n",
            "Epoch 20 Batch 100 Loss 0.0497\n",
            "Epoch 20 Batch 200 Loss 0.0709\n",
            "Epoch 20 Batch 300 Loss 0.0575\n",
            "Epoch 20 Batch 400 Loss 0.0813\n",
            "Epoch 20 Batch 500 Loss 0.0936\n",
            "Epoch 20 Batch 600 Loss 0.0801\n",
            "Epoch 20 Batch 700 Loss 0.0709\n",
            "Epoch 20 Loss 0.0606\n",
            "Time taken for 1 epoch 118.85608267784119 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6kO2HY0bEn0"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                           maxlen=max_length_inp,\n",
        "                                                           padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    enc_out, enc_hidden = encoder(inputs)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # 後ほどプロットするためにアテンションの重みを保存\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # 予測された ID がモデルに戻される\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnwoWfkYfwBZ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import japanize_matplotlib\n",
        "\n",
        "# アテンションの重みをプロットする関数\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-zIxy2Zf3vw"
      },
      "source": [
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIbzsxI-f8Z9",
        "outputId": "5a7915fc-e68e-46d4-d519-40f6aa966f81"
      },
      "source": [
        "# checkpoint_dir の中の最後のチェックポイントを復元\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd4b3130d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "aX4evgWVf9xa",
        "outputId": "05ae4622-7112-4d15-c89c-2af20923a7f9"
      },
      "source": [
        "translate('i was wrong .')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: i was wrong .\n",
            "Predicted translation: 私 は 良 かっ た で す ね 。 <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7_xsAt-QWXl"
      },
      "source": [
        "def predict(inputs):\n",
        "    inputs = tf.convert_to_tensor([inputs])\n",
        "    predicted_seq = []\n",
        "    \n",
        "    enc_out, enc_hidden = encoder(inputs)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # 後ほどプロットするためにアテンションの重みを保存\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        predicted_seq.append(predicted_id)\n",
        "\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return predicted_seq\n",
        "\n",
        "        # 予測された ID がモデルに戻される\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return predicted_seq\n",
        "    "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qYv1rYq1Lu5"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import pandas as pd\n",
        "\n",
        "input_sentences = []\n",
        "target_sentences = []\n",
        "predicted_sentences = []\n",
        "\n",
        "for i, input_en in enumerate(input_tensor_val):\n",
        "    predicted_ja = predict(input_en)\n",
        "    tokens_input = [inp_lang.index_word[id] for id in input_en if id > 2]\n",
        "    tokens_target = [targ_lang.index_word[id] for id in target_tensor_val[i] if id > 2]\n",
        "    tokens_predicted = [targ_lang.index_word[id] for id in predicted_ja if id > 2]\n",
        "    input_sentences.append(' '.join(tokens_input))\n",
        "    target_sentences.append(''.join(tokens_target))\n",
        "    predicted_sentences.append(''.join(tokens_predicted))\n",
        "\n",
        "result_df = pd.DataFrame({'input_sentence': input_sentences,\n",
        "                          'target_sentence': target_sentences,\n",
        "                          'predicted_sentence': predicted_sentences})  \n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COnhI7VyQWXp"
      },
      "source": [
        "bleu_scores = []\n",
        "for row in result_df.itertuples():\n",
        "    bleu_scores.append(\n",
        "        sentence_bleu(row.target_sentence, row.predicted_sentence,\n",
        "                      smoothing_function=SmoothingFunction().method4)\n",
        "    )\n",
        "result_df['bleu_score'] = bleu_scores"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOhwVunpl0nR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a969f355-0eff-4bc7-e228-cd8a9fe1385c"
      },
      "source": [
        "result_df"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_sentence</th>\n",
              "      <th>target_sentence</th>\n",
              "      <th>predicted_sentence</th>\n",
              "      <th>bleu_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i was wrong .</td>\n",
              "      <td>私が間違っていました。</td>\n",
              "      <td>私は間違っていた。</td>\n",
              "      <td>0.331186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>she is going to learn how to drive .</td>\n",
              "      <td>彼女は近く、運転を習うつもりでいます。</td>\n",
              "      <td>彼女は車を運転することが出来る。</td>\n",
              "      <td>0.314336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i am fond of skiing .</td>\n",
              "      <td>私はスキーが好きだ。</td>\n",
              "      <td>私はスキーが好きです。</td>\n",
              "      <td>0.336136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i will start working on july the first .</td>\n",
              "      <td>７月１日から仕事を始めます。</td>\n",
              "      <td>私は１日おきに出発するつもりだ。</td>\n",
              "      <td>0.264324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ken took the examination with confidence .</td>\n",
              "      <td>ケンは自信をもって試験を受けた。</td>\n",
              "      <td>ケンは試験に合格した。</td>\n",
              "      <td>0.315666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>either you or i am in the wrong .</td>\n",
              "      <td>あなたか私かどちらかが間違っている。</td>\n",
              "      <td>あなたかあるいは私が間違っている。</td>\n",
              "      <td>0.352381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>you 've got it in one . that 's right .</td>\n",
              "      <td>君はすぐに分かったんだね。そのとおりだよ。</td>\n",
              "      <td>君はそれを自分でできるのに気が狂い。</td>\n",
              "      <td>0.299767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>all you have to do is believe me .</td>\n",
              "      <td>君は僕を信じさえすれば良い。</td>\n",
              "      <td>君は私が正しいと言ってくれる。</td>\n",
              "      <td>0.281535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>i was embarrassed by what she said .</td>\n",
              "      <td>彼女の言葉を聞いてどぎまぎした。</td>\n",
              "      <td>私は彼女の言ったことをよく聞いた。</td>\n",
              "      <td>0.321431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>i can 't hear you .</td>\n",
              "      <td>聞こえませんよ。</td>\n",
              "      <td>君が想像できないのです。</td>\n",
              "      <td>0.192591</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  input_sentence  ... bleu_score\n",
              "0                                  i was wrong .  ...   0.331186\n",
              "1           she is going to learn how to drive .  ...   0.314336\n",
              "2                          i am fond of skiing .  ...   0.336136\n",
              "3       i will start working on july the first .  ...   0.264324\n",
              "4     ken took the examination with confidence .  ...   0.315666\n",
              "...                                          ...  ...        ...\n",
              "4995           either you or i am in the wrong .  ...   0.352381\n",
              "4996     you 've got it in one . that 's right .  ...   0.299767\n",
              "4997          all you have to do is believe me .  ...   0.281535\n",
              "4998        i was embarrassed by what she said .  ...   0.321431\n",
              "4999                         i can 't hear you .  ...   0.192591\n",
              "\n",
              "[5000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCRzYCWVqyk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4097692f-0489-4fd8-f1c6-ef80124ee2d4"
      },
      "source": [
        "result_df.bleu_score.mean()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31067805635914403"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilTTiC3yhDtZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}