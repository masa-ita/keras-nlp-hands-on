{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2859,
     "status": "ok",
     "timestamp": 1612533603852,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "QetvaJ27Tb6y",
    "outputId": "d5d13c9d-672a-497e-ebfc-b44b7e57965b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: japanize_matplotlib in /home/tensorflow/.local/lib/python3.6/site-packages (1.1.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from japanize_matplotlib) (3.3.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (7.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->japanize_matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install japanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_M-eDSyL-8E7",
    "outputId": "7f42f59e-e667-4f23-fa16-57d82dd3e4aa"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "url = 'https://github.com/odashi/small_parallel_enja/archive/master.zip'\n",
    "\n",
    "zip_file_path = get_file('small_parallel_enja.zip', url, cache_subdir='small_parallel_enja', extract=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SsrpAmZ1BVFF",
    "outputId": "4f86b029-427d-4f1a-e5bc-89a286ec9b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 9076\n",
      "-rw-r--r-- 1 tensorflow tensorflow    1946 Feb 11 10:10 README.md\n",
      "-rw-r--r-- 1 tensorflow tensorflow   17054 Feb 11 10:10 dev.en\n",
      "-rw-r--r-- 1 tensorflow tensorflow   27781 Feb 11 10:10 dev.ja\n",
      "-rw-r--r-- 1 tensorflow tensorflow   17301 Feb 11 10:10 test.en\n",
      "-rw-r--r-- 1 tensorflow tensorflow   27793 Feb 11 10:10 test.ja\n",
      "-rw-r--r-- 1 tensorflow tensorflow 1701356 Feb 11 10:10 train.en\n",
      "-rw-r--r-- 1 tensorflow tensorflow  339768 Feb 11 10:10 train.en.000\n",
      "-rw-r--r-- 1 tensorflow tensorflow  340186 Feb 11 10:10 train.en.001\n",
      "-rw-r--r-- 1 tensorflow tensorflow  341174 Feb 11 10:10 train.en.002\n",
      "-rw-r--r-- 1 tensorflow tensorflow  339953 Feb 11 10:10 train.en.003\n",
      "-rw-r--r-- 1 tensorflow tensorflow  340275 Feb 11 10:10 train.en.004\n",
      "-rw-r--r-- 1 tensorflow tensorflow   30025 Feb 11 10:10 train.en.vocab.4k\n",
      "-rw-r--r-- 1 tensorflow tensorflow   51162 Feb 11 10:10 train.en.vocab.all\n",
      "-rw-r--r-- 1 tensorflow tensorflow 2784447 Feb 11 10:10 train.ja\n",
      "-rw-r--r-- 1 tensorflow tensorflow  556444 Feb 11 10:10 train.ja.000\n",
      "-rw-r--r-- 1 tensorflow tensorflow  555732 Feb 11 10:10 train.ja.001\n",
      "-rw-r--r-- 1 tensorflow tensorflow  557218 Feb 11 10:10 train.ja.002\n",
      "-rw-r--r-- 1 tensorflow tensorflow  557538 Feb 11 10:10 train.ja.003\n",
      "-rw-r--r-- 1 tensorflow tensorflow  557515 Feb 11 10:10 train.ja.004\n",
      "-rw-r--r-- 1 tensorflow tensorflow   31009 Feb 11 10:10 train.ja.vocab.4k\n",
      "-rw-r--r-- 1 tensorflow tensorflow   73669 Feb 11 10:10 train.ja.vocab.all\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = os.path.join(os.path.dirname(zip_file_path), 'small_parallel_enja-master')\n",
    "!ls -l $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "y3iF78mDMb1B"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "TRAIN_SIZE_LIMIT = 30000\n",
    "TEST_SIZE_LIMIT = 300\n",
    "\n",
    "def load_data(path):\n",
    "    texts = []\n",
    "    for line in open(path, 'r'):\n",
    "        texts.append(line.strip())\n",
    "    return texts\n",
    "  \n",
    "def preprocess(text):\n",
    "    text = unicodedata.normalize('NFKC', text)\n",
    "    text = '<start> ' + text + ' <end>'\n",
    "    return text\n",
    "\n",
    "train_en = load_data(os.path.join(data_dir, 'train.en'))\n",
    "train_ja = load_data(os.path.join(data_dir, 'train.ja'))\n",
    "\n",
    "train_en = train_en[:TRAIN_SIZE_LIMIT]\n",
    "train_ja = train_ja[:TRAIN_SIZE_LIMIT]\n",
    "\n",
    "train_input = [preprocess(s) for s in train_en]\n",
    "train_target = [preprocess(s) for s in train_ja]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vectorizer = TextVectorization(max_tokens=20000,\n",
    "                                  standardize=None,\n",
    "                                  output_mode='int',\n",
    "                                  output_sequence_length=18)\n",
    "\n",
    "en_vectorizer.adapt(train_input)\n",
    "\n",
    "ja_vectorizer = TextVectorization(max_tokens=20000,\n",
    "                                  standardize=None,\n",
    "                                  output_mode='int',\n",
    "                                  output_sequence_length=18)\n",
    "\n",
    "ja_vectorizer.adapt(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ds = tf.data.Dataset.from_tensor_slices(en_vectorizer(train_input))\n",
    "train_target_ds = tf.data.Dataset.from_tensor_slices(ja_vectorizer(train_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.zip((train_input_ds, train_target_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "y3iF78mDMb1B"
   },
   "outputs": [],
   "source": [
    "en_vocab = en_vectorizer.get_vocabulary()\n",
    "ja_vocab = ja_vectorizer.get_vocabulary()\n",
    "vocab_inp_size = len(en_vocab) + 1\n",
    "vocab_tar_size = len(ja_vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "y3iF78mDMb1B"
   },
   "outputs": [],
   "source": [
    "max_length_inp = 18\n",
    "max_length_targ = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 20969,
     "status": "ok",
     "timestamp": 1612533622233,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "cfxSreRrXvw4"
   },
   "outputs": [],
   "source": [
    "def convert(vocab, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, vocab[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "en, ja = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20946,
     "status": "ok",
     "timestamp": 1612533622233,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "qBMUz4Q9Xxe7",
    "outputId": "dae0dde9-4b87-4f04-f9c0-83406ba9bfbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "2 ----> <start>\n",
      "6 ----> i\n",
      "41 ----> can\n",
      "22 ----> 't\n",
      "149 ----> tell\n",
      "136 ----> who\n",
      "29 ----> will\n",
      "709 ----> arrive\n",
      "231 ----> first\n",
      "4 ----> .\n",
      "3 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "2 ----> <start>\n",
      "92 ----> 誰\n",
      "14 ----> が\n",
      "239 ----> 一番\n",
      "7 ----> に\n",
      "161 ----> 着\n",
      "29 ----> く\n",
      "22 ----> か\n",
      "18 ----> 私\n",
      "7 ----> に\n",
      "5 ----> は\n",
      "290 ----> 分か\n",
      "39 ----> り\n",
      "21 ----> ま\n",
      "40 ----> せ\n",
      "30 ----> ん\n",
      "4 ----> 。\n",
      "3 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(en_vocab, en.numpy())\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(ja_vocab, ja.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 21908,
     "status": "ok",
     "timestamp": 1612533623222,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "ZDYSOGLzYbP8"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(train_input)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(train_input) // BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "\n",
    "dataset = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21906,
     "status": "ok",
     "timestamp": 1612533623225,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "OkZvi19gYp03",
    "outputId": "accb9126-2ff7-4c96-9d02-8cd62073cddd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 18]), TensorShape([64, 18]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 21881,
     "status": "ok",
     "timestamp": 1612533623226,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "YYHYgc4hYwly"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23528,
     "status": "ok",
     "timestamp": 1612533624879,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "v5fs_ECmZP8N",
    "outputId": "b516d329-0f71-4394-b486-d79e4a389450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 18, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# サンプル入力\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 23503,
     "status": "ok",
     "timestamp": 1612533624880,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "fRy4fGRXZU9P"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # スコアを計算するためにこのように加算を実行する\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # スコアを self.V に適用するために最後の軸は 1 となる\n",
    "        # self.V に適用する前のテンソルの shape は  (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "                      self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights の shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector の合計後の shape == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23787,
     "status": "ok",
     "timestamp": 1612533625170,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "QaX0KziyZoN5",
    "outputId": "bbb96965-3606-43a7-ee8a-11950147e010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 23763,
     "status": "ok",
     "timestamp": 1612533625171,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "yzuNjW0lZs1y"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # アテンションのため\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output の shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # 埋め込み層を通過したあとの x の shape  == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # 結合後の x の shape == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # 結合したベクトルを GRU 層に渡す\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23758,
     "status": "ok",
     "timestamp": 1612533625171,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "yP8fSgqDZ9Ci",
    "outputId": "28bed07a-7565-40d5-a52f-f6dc025ebf43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 6952)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 23733,
     "status": "ok",
     "timestamp": 1612533625172,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "xOmW4oGQaBuJ"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                             from_logits=True, reduction='none')\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 23729,
     "status": "ok",
     "timestamp": 1612533625173,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "j1xOnT6oaOCY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 23725,
     "status": "ok",
     "timestamp": 1612533625174,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "DaknH7tgaTEt"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([ja_vocab.index('<start>')] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher Forcing - 正解値を次の入力として供給\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # Teacher Forcing を使用\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1986767,
     "status": "ok",
     "timestamp": 1612535588222,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "5bNwa8eCa0Ru",
    "outputId": "d3629362-c291-47dc-8ec8-c49648190c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 6.1205\n",
      "Epoch 1 Batch 100 Loss 2.6564\n",
      "Epoch 1 Batch 200 Loss 2.3286\n",
      "Epoch 1 Batch 300 Loss 2.2678\n",
      "Epoch 1 Batch 400 Loss 2.2476\n",
      "Epoch 1 Loss 2.5152\n",
      "Time taken for 1 epoch 54.825743436813354 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.8989\n",
      "Epoch 2 Batch 100 Loss 1.9250\n",
      "Epoch 2 Batch 200 Loss 1.8727\n",
      "Epoch 2 Batch 300 Loss 1.8464\n",
      "Epoch 2 Batch 400 Loss 1.8113\n",
      "Epoch 2 Loss 1.8795\n",
      "Time taken for 1 epoch 36.00258159637451 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.5908\n",
      "Epoch 3 Batch 100 Loss 1.7378\n",
      "Epoch 3 Batch 200 Loss 1.7886\n",
      "Epoch 3 Batch 300 Loss 1.6569\n",
      "Epoch 3 Batch 400 Loss 1.5471\n",
      "Epoch 3 Loss 1.6218\n",
      "Time taken for 1 epoch 35.02392625808716 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.3151\n",
      "Epoch 4 Batch 100 Loss 1.3490\n",
      "Epoch 4 Batch 200 Loss 1.3743\n",
      "Epoch 4 Batch 300 Loss 1.2452\n",
      "Epoch 4 Batch 400 Loss 1.2473\n",
      "Epoch 4 Loss 1.3584\n",
      "Time taken for 1 epoch 35.90100336074829 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.0758\n",
      "Epoch 5 Batch 100 Loss 1.1607\n",
      "Epoch 5 Batch 200 Loss 1.1555\n",
      "Epoch 5 Batch 300 Loss 0.9708\n",
      "Epoch 5 Batch 400 Loss 1.0142\n",
      "Epoch 5 Loss 1.1083\n",
      "Time taken for 1 epoch 35.436342000961304 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.9121\n",
      "Epoch 6 Batch 100 Loss 0.8116\n",
      "Epoch 6 Batch 200 Loss 0.8035\n",
      "Epoch 6 Batch 300 Loss 0.8982\n",
      "Epoch 6 Batch 400 Loss 0.8625\n",
      "Epoch 6 Loss 0.8936\n",
      "Time taken for 1 epoch 35.70264744758606 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.6702\n",
      "Epoch 7 Batch 100 Loss 0.6721\n",
      "Epoch 7 Batch 200 Loss 0.9026\n",
      "Epoch 7 Batch 300 Loss 0.7088\n",
      "Epoch 7 Batch 400 Loss 0.7558\n",
      "Epoch 7 Loss 0.7126\n",
      "Time taken for 1 epoch 35.216952323913574 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.5980\n",
      "Epoch 8 Batch 100 Loss 0.5206\n",
      "Epoch 8 Batch 200 Loss 0.5894\n",
      "Epoch 8 Batch 300 Loss 0.6228\n",
      "Epoch 8 Batch 400 Loss 0.6692\n",
      "Epoch 8 Loss 0.5618\n",
      "Time taken for 1 epoch 35.708061933517456 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.4565\n",
      "Epoch 9 Batch 100 Loss 0.4294\n",
      "Epoch 9 Batch 200 Loss 0.4012\n",
      "Epoch 9 Batch 300 Loss 0.4475\n",
      "Epoch 9 Batch 400 Loss 0.4109\n",
      "Epoch 9 Loss 0.4322\n",
      "Time taken for 1 epoch 35.18329071998596 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.2578\n",
      "Epoch 10 Batch 100 Loss 0.2605\n",
      "Epoch 10 Batch 200 Loss 0.3044\n",
      "Epoch 10 Batch 300 Loss 0.4032\n",
      "Epoch 10 Batch 400 Loss 0.3971\n",
      "Epoch 10 Loss 0.3284\n",
      "Time taken for 1 epoch 36.05557656288147 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.2177\n",
      "Epoch 11 Batch 100 Loss 0.2417\n",
      "Epoch 11 Batch 200 Loss 0.2564\n",
      "Epoch 11 Batch 300 Loss 0.2441\n",
      "Epoch 11 Batch 400 Loss 0.2497\n",
      "Epoch 11 Loss 0.2475\n",
      "Time taken for 1 epoch 35.37613773345947 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.1719\n",
      "Epoch 12 Batch 100 Loss 0.1500\n",
      "Epoch 12 Batch 200 Loss 0.2019\n",
      "Epoch 12 Batch 300 Loss 0.1917\n",
      "Epoch 12 Batch 400 Loss 0.1744\n",
      "Epoch 12 Loss 0.1863\n",
      "Time taken for 1 epoch 35.796715259552 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.1014\n",
      "Epoch 13 Batch 100 Loss 0.1369\n",
      "Epoch 13 Batch 200 Loss 0.1263\n",
      "Epoch 13 Batch 300 Loss 0.1344\n",
      "Epoch 13 Batch 400 Loss 0.1655\n",
      "Epoch 13 Loss 0.1427\n",
      "Time taken for 1 epoch 35.068371295928955 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0863\n",
      "Epoch 14 Batch 100 Loss 0.0797\n",
      "Epoch 14 Batch 200 Loss 0.1316\n",
      "Epoch 14 Batch 300 Loss 0.1285\n",
      "Epoch 14 Batch 400 Loss 0.1099\n",
      "Epoch 14 Loss 0.1177\n",
      "Time taken for 1 epoch 36.032644271850586 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0955\n",
      "Epoch 15 Batch 100 Loss 0.0894\n",
      "Epoch 15 Batch 200 Loss 0.0855\n",
      "Epoch 15 Batch 300 Loss 0.0912\n",
      "Epoch 15 Batch 400 Loss 0.1218\n",
      "Epoch 15 Loss 0.0979\n",
      "Time taken for 1 epoch 35.50360679626465 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0802\n",
      "Epoch 16 Batch 100 Loss 0.0885\n",
      "Epoch 16 Batch 200 Loss 0.0914\n",
      "Epoch 16 Batch 300 Loss 0.1033\n",
      "Epoch 16 Batch 400 Loss 0.1205\n",
      "Epoch 16 Loss 0.0874\n",
      "Time taken for 1 epoch 35.70587229728699 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0667\n",
      "Epoch 17 Batch 100 Loss 0.0704\n",
      "Epoch 17 Batch 200 Loss 0.0645\n",
      "Epoch 17 Batch 300 Loss 0.0903\n",
      "Epoch 17 Batch 400 Loss 0.1025\n",
      "Epoch 17 Loss 0.0813\n",
      "Time taken for 1 epoch 35.213725566864014 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0798\n",
      "Epoch 18 Batch 100 Loss 0.0582\n",
      "Epoch 18 Batch 200 Loss 0.0616\n",
      "Epoch 18 Batch 300 Loss 0.0803\n",
      "Epoch 18 Batch 400 Loss 0.1104\n",
      "Epoch 18 Loss 0.0778\n",
      "Time taken for 1 epoch 35.72765564918518 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0653\n",
      "Epoch 19 Batch 100 Loss 0.0916\n",
      "Epoch 19 Batch 200 Loss 0.0706\n",
      "Epoch 19 Batch 300 Loss 0.0814\n",
      "Epoch 19 Batch 400 Loss 0.0770\n",
      "Epoch 19 Loss 0.0756\n",
      "Time taken for 1 epoch 35.15982532501221 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0629\n",
      "Epoch 20 Batch 100 Loss 0.0837\n",
      "Epoch 20 Batch 200 Loss 0.0646\n",
      "Epoch 20 Batch 300 Loss 0.0686\n",
      "Epoch 20 Batch 400 Loss 0.0737\n",
      "Epoch 20 Loss 0.0754\n",
      "Time taken for 1 epoch 35.86249828338623 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "              print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "    # 2 エポックごとにモデル（のチェックポイント）を保存\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 1986744,
     "status": "ok",
     "timestamp": 1612535588224,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "H6kO2HY0bEn0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "en_word_index = {w:i for i,w in enumerate(en_vocab)}\n",
    "\n",
    "def evaluate(sentence):\n",
    "    sentence = preprocess(sentence)\n",
    "    \n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    inputs = [en_word_index.get(w, 1) for w in sentence.split(' ')] # index 1 for [UNK]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([ja_vocab.index('<start>')], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # 後ほどプロットするためにアテンションの重みを保存\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        if ja_vocab[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        result += ja_vocab[predicted_id] + ' '\n",
    "\n",
    "        # 予測された ID がモデルに戻される\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 1986740,
     "status": "ok",
     "timestamp": 1612535588225,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "tnwoWfkYfwBZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import japanize_matplotlib\n",
    "\n",
    "# アテンションの重みをプロットする関数\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 1986735,
     "status": "ok",
     "timestamp": 1612535588226,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "q-zIxy2Zf3vw"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1986983,
     "status": "ok",
     "timestamp": 1612535588478,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "mIbzsxI-f8Z9",
    "outputId": "59c2afce-8f46-45af-c773-e8be712eb93a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0fe586c550>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_dir の中の最後のチェックポイントを復元\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "executionInfo": {
     "elapsed": 1987264,
     "status": "ok",
     "timestamp": 1612535588788,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "aX4evgWVf9xa",
    "outputId": "831a9943-b7d0-4458-c854-0203c14ea490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> i am a little out of sorts today . <end>\n",
      "Predicted translation: 今日 は 少し 気分 が 悪 い 。 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAIRCAYAAAB07dgBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnwklEQVR4nO3deZhkZ1328e89S2YyGbJvkBCSEBIM2TSBCAivyCZuuCIoi0CckBdEg5F9My+KmGgUATUii1FACTsBRRRFJQFGkC1AgKyQBbKRZZJZMr/3j1MNbadnpmem6jlV1d/PdfVF1Tmnuu6HdE/dfZbnpKqQJElSG0v6DiBJkrSYWL4kSZIasnxJkiQ1ZPmSJElqyPIlSZLUkOVLkiSpIcuXJElSQ5YvSZKkhixfkiRJDVm+BpL8Z5If7zuHJEmabpYvIMlDgMuB5/YcRZIkTTnLV+d5wMuAy5M8sO8wkiRpei368pXkKKCq6jLgHOB3eo4kSZJGIMlDkqzuO8eiL1/AGcAfA1TV14BlSY7oN5IkSRqmJCuA84DT+s6yqMtXkgOBI6vqwlmL/5SukEmSpOnxNOBs4KeSLO8zyKIuX3Qn2L9u9oKq+nfgmCT79xNJkiQNU5IATwXeBPwD8JQ+8yz28vUd4Px5lp8JWL4kSZoOPwv8a1WtB94MPKPPMKmqPt+/d0lWV9Vt8yxfVVXr+sgkSZKGJ8nHgCdU1XcGz38fuKiq3t9HnsW+5wvg4rkLkuwF/HMPWSRJ0hAl+RHg0pniNfBnwOk9RWJZX2/ctyT3BkJ3dePM4xkHAPfrJZgkaWIlObSqLu87h/6X5wMvnL2gqq5JcmWSh1TVJ1oHWrSHHZP8E/BooPjfxQtgHfDaqnpx82CSpImVZBPdkZO/AD5QVZt7jrTobakQDy6su6Wq7myeabGWrxlJvlJV9+87hyRp8iU5EvhV4FeAXemurvurqrqq12AaK5av5Feq6m1955AkTZckPww8EfgF4HN0e8MuqMX+wdtIkgVd0VhVbxp1lrksX8mXgB+sqg19Z5EkTY8kPwY8Hfhx4F+Ao+n2hj2pqtb2mW0xSHLZnEX3Bm4CbgP2BJYC/1NVD28czasd6W4z8OdJDuk7iCRpsiW5T5JXJLkU+Bvgq8ADquqJVXUc8HrgLX1mXCyq6rCZL+As4Jyq2m/w/EDgg8Bf95HNPV/JhXR/iRwLXAvcNbOuqixkktRAkqOAFVX1+ST3AF4N7AG8eJLOl0pyF/BJuqkM3llVm+as3w04q6r+bx/5FqskFwPHV9XGWctWA/9dVUe1zrNop5qY5S/6DiBJ4hy62758nm4vxX2Az9LtJXpkf7G228lbO6RYVbcDFq/29gLmXnm6ge7wY3OLfs+XJKl/Sa6tqgOTrAIuB46oqluSXDlpRyGSHA0cD8zcvHkVcExVPae/VItbkvcA3wWeO/i52ht4LbCyqn6xdR73fPG9Ge3vz91/Uc7uL5U0npIcCxxeVe9LcnBVfbPvTJoK65LsTnfD448OPiB3B3bpOdd2SXIa3V68i+k+Vz4PHEN3GFX9eQ7wHuDGJDfR7Qn7EvDYPsIs+vKV5OeBvwXuBFYDN9KdZ/DWPnNJ42YwIeE7gAcDtwLvA16X5O+r6u29htM0eD1wFd2hoYcOlr0EeHdviXbM7wAPrqrPJrm8qn44yS/R/d6oJ1X1rcHUHycBhwHXAP/Z1yS4i/6wY5KvAGdU1QcHvyiHJvktul2Rf9BzPGlsJHkb3WXaZwAXV9Vhg6uE31dVP9hvOk2DwUn3N1fVdYPn9weurqpb+k22cEm+VVUHDR5/Aziyqu5KctngKjvJqSaAe1TVBwePZ650/FPglJ7ySOPqocBvVNUddLfloqquBPbpNZWmQpKXV9VXZ4rXwDXAL/WVaQddnOQFg8eXAT+Z5J7Ayh4zLXpJjkjyriSXDO7p+L2vPvJYvuDKJE8cPL46ycPoDj+u7jGTNI42050nAYP7oSY5EFjfWyJNk7v9wVtV36U79DhJng08Jkno5pB6N/A1nNurb2+hO9XqbOBlc76aW/TnfAG/BbwlyTvpzmf5AHAz8KEeM0nj6F3ABUl+A7qb1dJN1fKOPkNpsiU5i27v6V5J5t7mZX/uPj3AWKuqS/j+1BhvT3I5sKqq/qW/VAKOAB42Lrd2WvTnfAEkWT4z8dpgL9huwFvnTo4nLWZJdqWbsfsXBouK7uqhX62qidn7leTRVfXPc5btQneF82d6irVoJfkp4ETgecAfz1m9Dnh3VX2jeTBNlSSfAX50XM4fXPTlK8nTq+rNc5atBh5eVe79kuZIchBwCPDNSZp5fMZ880YNiuWnq+qYnmIteknWVNW5fefYEUnOXMh2VfXyUWfR/JI8jm66iWcB35q9ro8rHi1f8/9DvBT4clUd2VMsSUOW5JeBFXR7V543Z/X+wPOrav/mwQRAkk9V1YP6zrEjknxs1tMldBenfA64BTgAOIjuquCn9hBPQJLv0E0jtXTuuqq627JRW7TnfCV5Ht1J9bsnmfvXyP50hx7VgyQrgGcCJzDnCiH/8WoryX8wuLJxa6rq4Q3i7KyjgEfQ/d4/fc66dcCa5ok028VJHlFVH9v2puOlqh4x8zjJK4D3VtU5s5b9EfDtPrLpe5rPYr81i3bPV5JT6P46+SXgnXNWrwPOq6qLmgcTSc6j+29zId29t76nquZ+aGqEBh8k21RVvzvqLMOS5M3+HI2fJD8JnEZXUi7k+1P/UFVzT8QfW0kuAY6afWL34A/Ki6vqvv0l0zhZtOVrRpIzPQ4/XpJcA9yvqm7rO4ukNpJctoVVVVWHNw2zEwb/fh0xuIH2zLLdgUuq6sD+kinJ/ejO+Tqoqp6Y5Fl0O1pu38ZLh27RHnac5cwkK6vqToAkDwR297LgXl1Dd39Ny9cYSfKFqjp2zrK96P7x+qmeYm23JH+zpXUe1u7PFM3+/hHgPYNTWy4DjqSbW+qDW32VRirJo+imy3kP8LDB4n2BPwB+o3Ueyxe8iu6WKa9J8jTgT4Drk7yzql7ca7LF6xTg/Un+Hrhh9oqq2uIHp0Zuz3mWLaObJmCS3DXn+aHAA4E3tI+iuZIspztJ/dtVtWFb24+h3wTeRHdD7aKbkPjDwOl9hhJ/ADy+qv5t1l7WPwS+Qg/ly8OOyVXAsVV1c5KvA08Cvsjg3nX9pluckrwMeAVwLbBx1qqJOvwwLZJcRFdOtuRtVfWUVnlGYXA/1wOr6oV9Z9mWwa1r3lBVt/adZZgGM8KfSXcl6kq6Oye8nu4q1In7oEqyH3A4cM3gNlzq0Zx7bl4681mS5JtVdXDrPN5eqPtAvznJQ4Hrq+rTdL/09+g512L2XOC4qjq4qg6b9WXx6sdjgfsC19F9mMz+OnDSixdAVf0JY3Y11FY8e6Z4JVnbd5ghejbwBODJwDGD//0puruQTKIjgfsB9+k7iAC4LsljZi9I8mPAN/sI42FH+O8kb6X7y/7Vg2U/D3yhv0iL3g1090LTGBjcX++7SX6xqq6Yuz7JwVXVyz9gw5LkEGDXvnMs0F2Dc1M/Axww2GOUuRv1MXHkTjoNeGxVXT54/uXBrOQfAs7Z4qvGzGCS7g8DDwGuB/ZN8mm6sX2313CL25nAe5O8GbhHklfSHW58ch9h3PPVzSd1NfD6qjpvsGx/4EX9RVr0fg94R5Ljkxw++6vvYIvc3e7hmGRP4P3to+y4JP+R5OOzvi4EvkR366RJ8Bq+Pw3LvYBNdIfn535Nmt1nFS8ABs9X95Jmx/0+8B1g/6o6gO7z5Cq+/8e9elBV76Xbs3o/4Ea6k+5/rao+3EeeRX3OV5InVNU/zLP8RODGqtrSpc8aoSRb+ou9+piJeLEbHJJfCpxPd1/H2XtZDqA7/2i/PrLtiHnmLrsT+FxV/WMfeXZEkoPpDvueTzdX4d1U1b83DbWTBiX4JVX1r7OWPQJ4zSTNfD84d/j4OVNN7AZ83nm++jGOn/WL/bDjjya5ae5Ndun+cjm1j0ACwAsdxsuvAY+iu9px7t6hdcAr28bZOVX1u0kOoLuq9jDgSibsNIPBYd5vJnku3dVas8fy11X1ra29fky9HPhgkjfRjelIuiMTP99rqu23fJ55o9YBy/sII2AMP+sX+56v+wKvraqfnLXsBOCFVfXE3oJp5iaoJ/D9f7BWAcdM0nxSM6ZlLEn+uaoe3XeOnTX4vb+Qbj65r9DddugQ4MFV9dU+s22vrYzlh6vqkj6z7YgkjwV+m276jyuAc6rqQ72G2k5J3gt8sqpePWvZC4CHTdrv/LQYx8/6RX3OV1V9A7g9yQNmLT6d7pwK9STJmcDf0l0EcQZwNN1f9u/pM9eOmKaxTEPxGjib7kP9+Kr65ao6gW4OoLP7jbVDtjSWP+o31vZLcjKwoaoeAzyc7py2FyU5rt9k2+23gecl+UKS85N8Hng+d7+ZuxoZx8/6Rb3nC743o/2pVXVKknsBb6yqn+g712KW5Aq6vxKvTHJ5VR2a5OHAM6vqaX3n2x6TPpYkvzWYhoEkW5z9fZImv5357zDP8iuqaqKmBZiysfwHcFZVvT/JO+gO1V1E97tycr/pFi7J0+mudnwm3TQTVwJvoZs+Z6L24k2TcfusX/TlCyDJPwJPpZtP5t+q6iP9JlrcknwLOLiqKsnX6A7RrU9yZVUd0ne+7THpY0nyiap6yODxtNx77xt0Eyuvm7VsN+ALkzQOmLqxXFNV9xzcsuorwCGD35WrqurefedbqPl+t5MsBb5cVUf2FEuM12f9Yj/hfsZrgRcAJ5S3FBoHFwJ/luQ3ga8CTx/Msn63uYwmwESPZaZ4DR5Py4UQHwL+LskpVXVDkn2Ac+n2VkyaaRrLLUkOBZ4BvHdQvA7oOdOCpbuX42pg9yQvn7N6f2C39qk0x9h81lu+gKr6UJI/oLvyYaIkObuqzhg8nvsL/z1VdWa7VDvt2cCrq+quJK8FLqA7P3ES74020WMZnLO2LVVVc6dvGGcvpisn305yE7AX8Cng6b2m2jHTNJbfBS4Bvg08eLDsRcB5W3zFeLkFOJbuc3XuHyrr6KZpmRqzP3smxTh91nvYcWCwq/vmmrD/Q5L8Q1U9YfD4Y1vYrKrqxxrGGqokBwG7VtXX+86ysyZtLFv5mZptIn++BvOXzZyT81+T9rs/27SMZXDIdENVbRw8P5BuHqaJucF2kjOraot/CE+L2ackTJJx+ay3fEmSJDW0qKeakCRJas3yJUmS1JDla44ka/rOMAzTMg5wLONoWsYBjmVcTctYpmUc4FiGyfJ1d9PywzUt4wDHMo6mZRzgWMbVtIxlWsYBjmVoLF+SJEkNTczVjrtkRa1sMEfdRtaznBUjf59Rm5ZxgGMZR9MyDnAs46rFWJLRz3W8gfXsMur/JsvaTNm5YfMd7LJk15G+x/p7txnLXbfcztLdR9sp1l969fVVtd986yZmktWV7MbJeWTfMSRp+zX4kG8m03PAZMkuy/uOMBRL9tm77whDc+kf7tN3hKG55BdfccWW1k3Pb5EkSdIEsHxJkiQ1ZPmSJElqyPIlSZLUkOVLkiSpIcuXJElSQ5YvSZKkhixfkiRJDVm+JEmSGrJ8SZIkNWT5kiRJasjyJUmS1JDlS5IkqSHLlyRJUkOWL0mSpIYsX5IkSQ1ZviRJkhraofKV5KAk30lySZI9trLdaUlu3sbXaTseX5IkabJsd/lKshw4D3gt8G7g/CSrtrD5CuC9VbXnfF/AewfbSJIkLQrbVb6SLAPeAdwF/D7wIuAbwEeTHDD8eJIkSdNlweUryUHAx4DdgJ+pqruq8yzgfcBnk/zSiHJKkiRNhW2WryS7JDkd+AzwL8Bq4LIk1858AacDjwdenOSiJIeNNLUkSdKEWraAbfYF7g/8SFV9DXjlljZMciLw08CVsxb/SpKf3cJLVgH/s5CgkiRJ02Cb5auqrgZOTXJGkjO2timwpqreN2f526rq1+Z7QZK3bO29k6wB1gCsZEvn9EuSJE2Ohez5AqCqzgbOnm9dkuOBjwNfG1Kumfc8FzgXYPfsXcP83pIkSX3Y6UlWB9NMvB14VVV9ZecjSZIkTa+dKl9JlgBvBC5lC3vFJEmS9H0LPuw4V5KlwFuAB9CdjL+lw4KecC9JkjSww+ULOBE4HHh0Vd26hW3+Dnh3VV0538okhwB37EQGSZKkibLD5auqPgU8dBvbfGcb6+ctZZIkSdNqp0+4lyRJ0sJZviRJkhqyfEmSJDVk+ZIkSWrI8iVJktSQ5UuSJKkhy5ckSVJDli9JkqSGLF+SJEkNWb4kSZIasnxJkiQ1ZPmSJElqyPIlSZLUkOVLkiSpIcuXJElSQ5YvSZKkhixfkiRJDVm+JEmSGlrWd4AFW7WSPOCYvlMMxZJLruw7wlDcddvtfUcYntrcdwJNsSxd2ncEzWfJdOx/uPHhh/QdYWg23Lm+7whNTMdPniRJ0oSwfEmSJDVk+ZIkSWrI8iVJktSQ5UuSJKkhy5ckSVJDli9JkqSGLF+SJEkNWb4kSZIasnxJkiQ1ZPmSJElqyPIlSZLUkOVLkiSpIcuXJElSQ5YvSZKkhixfkiRJDVm+JEmSGrJ8SZIkNWT5kiRJamjk5SvJ05P8+TzL75fkylG/vyRJ0jhpsefrYcB18yzfCCxr8P6SJEljo0X5Ogn4BECS3ZKsGCzfCOyS5MQkpya5Z4MskiRJvRpp+UqyDLg/8D+DRS8GbkmyHrgM2Bt4C/A4YNdRZpEkSRoHoz7sdxCwrqq+DVBVLwFeApBkL+CKqjp2xBkkSZLGxqgPOx4IXL2FdRuAXUb8/pIkSWNl1OVrV+C2JD+Q5AFz1m0Alm/txUnWJFmbZO3GTetGFlKSJKmVUZevO+kObZ4N7JlkryRvT3IZsBZYkuT4Lb24qs6tqpOq6qTly1aNOKokSdLojbp8fZfuhPt9q+q/gNcAXx4s+zlgM/CRJO9Mcq8RZ5EkSerdqMvXlXSHHv9+8Pweg/fcBOwF3AQcCawH3jTiLJIkSb0b6dWOVXV7kquBLwwWvRT4S+B6usL1/Kr6LvDkJHuPMoskSdI4aDHD/OFVtR6gqr4BPGq+jarqxgZZJEmSejXyGe5nipckSZLa3F5IkiRJA5YvSZKkhixfkiRJDVm+JEmSGrJ8SZIkNWT5kiRJasjyJUmS1JDlS5IkqSHLlyRJUkOWL0mSpIYsX5IkSQ1ZviRJkhqyfEmSJDVk+ZIkSWrI8iVJktSQ5UuSJKkhy5ckSVJDy/oOsFC1fAl3HrBr3zGGYsVnbu87gubK9PwdkuUT82u9TVk2JWOp6jvB0GTFir4jDM26hxzRd4Sh2LQyfUcYml1329B3hCam5xNHkiRpAli+JEmSGrJ8SZIkNWT5kiRJasjyJUmS1JDlS5IkqSHLlyRJUkOWL0mSpIYsX5IkSQ1ZviRJkhqyfEmSJDVk+ZIkSWrI8iVJktSQ5UuSJKkhy5ckSVJDli9JkqSGLF+SJEkNWb4kSZIasnxJkiQ1ZPmSJElqyPIlSZLU0A6VrySvS/LKBWz3Q0nW7ch7SJIkTaMFl68kByTZbZ7lj09yny28bCmwaUfDSZIkTZvt2fP1Z8AL5ll+P+CCJHvMs24pcNeOBJMkSZpGCypfSfYCfhp4+9x1VXU28GngHUkyZ7XlS5IkaZaF7vn6TeDjVfXlLax/NnBf4PQ5yy1fkiRJs2yzfCV5IPDCwdd86/cC3gb8X+CUJMtmrd6p8pVkTZK1SdZu3HD7jn4bSZKksbGQPV8/Crymqj6bZPWgXO0G1GD9q4DbquqjwA9W1ewT7LdavpLsurU3rqpzq+qkqjpp+S53O9dfkiRp4izb1gZVddaspz8BvHHw+FeTPB54AnDMYNv1c16+BNg83/dNcjLwV0lOqKp5t5EkSZo22zXPV1X9Q1XtXlW7A6uBc4Efr6rrtvCSm4E9556In+S+wPnAWy1ekiRpMdnuSVaTHJXkXcD/Ax5TVf+9lc2/BGwEfifJ7kn2TfIs4JPAeVX1RzuUWpIkaUItdKqJI5M8N8kFdMXpM8ADqupzW3tdVd0O/DzwZOBG4FrgV4CnVtWLdyq5JEnSBNrmOV8Dj6I78f7vgCdW1a0LfYOq+jhwXJLl3dNyxntJkrRoLah8VdUbgDfszBtV1cadeb0kSdI02KEba0uSJGnHWL4kSZIasnxJkiQ1ZPmSJElqyPIlSZLUkOVLkiSpIcuXJElSQ5YvSZKkhixfkiRJDVm+JEmSGrJ8SZIkNWT5kiRJasjyJUmS1JDlS5IkqSHLlyRJUkOWL0mSpIaW9R1gobKpWHHD+r5jaJYsSd8RhqY2V98RhmbJqlV9RxieafkZm6Kfr6zYpe8IQ1OZjp+vpRum5+drz1V39B2hCfd8SZIkNWT5kiRJasjyJUmS1JDlS5IkqSHLlyRJUkOWL0mSpIYsX5IkSQ1ZviRJkhqyfEmSJDVk+ZIkSWrI8iVJktSQ5UuSJKkhy5ckSVJDli9JkqSGLF+SJEkNWb4kSZIasnxJkiQ1ZPmSJElqyPIlSZLU0ILLV5IHJrnXKMNIkiRNuwWVryS7AhcAh2zvGyT58SQvHDy+T5J/SbJ8e7+PJEnSNFjonq9TgeXA3yb5+la+fmCe174UuB6gqq4A7gSeP5T0kiRJE2bZtjZI8kDgJcArgFu2sNltVXX+PK99InAw8NZZi58NfDrJf1XVv213YkmSpAm2zfIFPAn4ZeAO4IAtbLNu7oIkhwJ/AjytqjbOLK+qy5M8E3hXkp+oqk9ub2hJkqRJtZDydSvwpm1scy3wkZknSQ4EPgy8uar+ae7GVfX+JC8C/jnJqVX19u3ILEmSNLG2ec5XVb0COAI4rKoOrapDgROBvx48Phk4dGb7wRWRa4GPA7+e5Poktye5c/D4+iQ3A88BngWck2TePWpJ1iRZm2Ttxo2378w4JUmSxsL2nHD/H0mOGTx/LnDU4PFGYOXMhlV1NfDrVXVqVe1bVfsCbwZePev5E+jOE3sbcHhVXTffm1bVuVV1UlWdtHz5bts/OkmSpDGzkMOOVNXrk1wJfCDJBXTngT1wsPpWYHWSJVW1ebD9h+d8iwcBr5r1fE/gtsG2dztfTJIkaVoteJLVqvoA8DjgFOC7wKbB8o3ATcD+SZ6VZOXs1yU5CTgS+NisxfsNXiNJkrSobM8M98cC/wj8PvDXwEVJHjRY/QXgGLopKVbNes0q4E+Bv6yqW2d9u4MZzP0lSZK0mCxknq9DgZcBjwfOqKq3DJZfBnwoydHA+4FXAuuq6sbB+sOBvwE2Ay8fPL+Jbo/ZI4B3D3kskiRJY28he74OoTvMeNRM8QIYnCz/gKr6NvBGYHe6vVwkeRJwMfA54DFVtR54BnAVcDNwT+A9QxuFJEnShNjmnq+q+jjdtBHzrbtu8L+3AcfNWvVu4KKqumzWti+lu9WQJEnSorWgqx2312BP12Xb3FCSJGmRWfAJ95IkSdp5li9JkqSGLF+SJEkNWb4kSZIasnxJkiQ1ZPmSJElqyPIlSZLUkOVLkiSpIcuXJElSQ5YvSZKkhixfkiRJDVm+JEmSGrJ8SZIkNWT5kiRJasjyJUmS1JDlS5IkqaFlfQdYqA17LOGKx63uO8ZQHLo2fUfQHFkyPf9NNq9b13eEocnSpX1HGI5pGQeQPXfvO8LQ3Hj0xHwEbtWmlX0nGJ4D/nSfviM04Z4vSZKkhixfkiRJDVm+JEmSGrJ8SZIkNWT5kiRJasjyJUmS1JDlS5IkqSHLlyRJUkOWL0mSpIYsX5IkSQ1ZviRJkhqyfEmSJDVk+ZIkSWrI8iVJktSQ5UuSJKkhy5ckSVJDli9JkqSGLF+SJEkNjUX5SvLUJA/vO4ckSdKoNS1fST6Q5AFzlr0UuBz4yyQntMwjSZLUWrPylWQV8DjgmlnLdgE+DfwF8FygWuWRJEnqQ8s9XycDl1TVjQBJAlwELAPOAr5YVZ9rmEeSJKm5ZaP85kl+FPg54DDgeOBeSa4HvgI8DTgDOB/4kaq6ZgvfRpIkaWqMes/XZuCbwBuA9cDjgf3oDjX+XlX9K3AO8NYkY3HyvyRJ0iiNtPBU1cer6izgG8A+wEerqoALgOMGm50FHAA8Y5RZJEmSxkGrvU1PA95RVRsGz2vmvavqTuClwN5zX5RkTZK1SdbedfvtjaJKkiSNzkjP+QJIsgI4BXjkrMX7ANfPPKmqv5nvtVV1LnAuwMqD7u2VkJIkaeK12PN1CvClqvrSrGXHAxc3eG9JkqSxMuqrHfegO6T4q0keCqwEvgA8CTh9lO8tSZI0jka95+tk4MLBVY2bgb8CrqMrYB8c8XtLkiSNnZHu+aqqjwAfGTy+EDg8yW5V5dnzkiRpUWo+t5bFS5IkLWZObCpJktSQ5UuSJKkhy5ckSVJDli9JkqSGLF+SJEkNWb4kSZIasnxJkiQ1ZPmSJElqyPIlSZLUkOVLkiSpIcuXJElSQ5YvSZKkhixfkiRJDVm+JEmSGrJ8SZIkNWT5kiRJasjyJUmS1JDlS5IkqaFlfQdYqBXX3sFhZ3+h7xhDUUuX9h1hKJbsuUffEYam7rlv3xGGZskt6/qOMDSXPuVefUcYikP+6ba+IwzNTfdd1XeEoVk2Jb8qq6/a3HeEoVl2x119R2jCPV+SJEkNWb4kSZIasnxJkiQ1ZPmSJElqyPIlSZLUkOVLkiSpIcuXJElSQ5YvSZKkhixfkiRJDVm+JEmSGrJ8SZIkNWT5kiRJasjyJUmS1JDlS5IkqSHLlyRJUkOWL0mSpIYsX5IkSQ1ZviRJkhqyfEmSJDW0bJTfPMmngL1nLToUuJKu9N0TuGrWuk1Vdf9R5pEkSerbSMtXVT1o9vMk1wI/BOwJfLCqjhnl+0uSJI2bkZYvgCT/BtwL2ADsA3wCWArcJ8kXB4/XV9UJo84iSZLUtxbnfC0Dfmawl+sG4CHAY4GvD5Y9ggYlUJIkaRy0Kj2vS3Ib3eHGvwOWA4ckeS+wolEGSZKk3rUoXz8D7DJ4/HngdGAP4DzgWYPlGxvkkCRJ6t3IyleSg4B/n7N4b+Af+f7Vjv85a3uAn66qL89atgZYA7Ayu40qqiRJUjMjK19V9S3giLnLk+wN7F1VXx8837Oqbt7C9zgXOBdgj6X71qiySpIktdLiasdfBL4JPBK4FtgMPD/JCVW1HvhwkvdU1R+OOoskSVLfRnq1Y5LlwDnAJmA/YK+qejPwNeDXkhwNnA28IMkvjDKLJEnSOBj1VBOvBL5aVWuBAnYdLH8y8EbgKcCDgF8H3pjkgBHnkSRJ6tWoDzseApw2ePyfwF8k+W26IrYMuB54UlVdlOSWqrpuxHkkSZJ6NerbCz1l1uN3Ae/ayrYfHWUWSZKkcdBihntJkiQNWL4kSZIasnxJkiQ1ZPmSJElqyPIlSZLUkOVLkiSpIcuXJElSQ5YvSZKkhixfkiRJDVm+JEmSGrJ8SZIkNWT5kiRJasjyJUmS1JDlS5IkqSHLlyRJUkOWL0mSpIYsX5IkSQ1ZviRJkhpa1neABUvIssmJuzWbb1/Xd4ShyPLlfUcYng2b+k4wNLcdvX/fEYZm9ZXVd4ShWHLHxr4jDM2eF9/ad4ShWX/Aqr4jDMXKq6fnv8nmlVP0ubIV7vmSJElqyPIlSZLUkOVLkiSpIcuXJElSQ5YvSZKkhixfkiRJDVm+JEmSGrJ8SZIkNWT5kiRJasjyJUmS1JDlS5IkqSHLlyRJUkOWL0mSpIYsX5IkSQ1ZviRJkhqyfEmSJDVk+ZIkSWrI8iVJktSQ5UuSJKkhy5ckSVJDIy9fSQ5OsnTU7yNJkjQJRlq+kiwBrgLuO8+6JPmZJLuMMoMkSdI4GWn5qqrNwGZgvj1fAZ4DvGqUGSRJksZJi3O+bgNWz104KGZPBp6R5P80yCFJktS7FuXrBmDv+VZU1beBM4Fz5lufZE2StUnWbqg7RxhRkiSpjRbl6yrgkK2s/yvg4CSPmLuiqs6tqpOq6qRdsnJkASVJklppUb6+CBw38yTJo2df/VhVdwB/C5zeIIskSVKvWpSvjwA/Mbi6cQXwNuBBc7Z5HZYvSZK0CCxr8B4XAK8BXkx34v3Xq+rC2RtU1aUNckiSJPVu5OWrqjYl+VngnYP3e/yo31OSJGlctdjzRVV9BTi2xXtJkiSNM+/tKEmS1JDlS5IkqSHLlyRJUkOWL0mSpIYsX5IkSQ1ZviRJkhqyfEmSJDVk+ZIkSWrI8iVJktSQ5UuSJKkhy5ckSVJDli9JkqSGLF+SJEkNWb4kSZIasnxJkiQ1ZPmSJElqyPIlSZLUkOVLkiSpoWV9B1io2nwXm2+9te8Yw7H5rr4TDMXmm27uO8LQZOPGviMMzW4bN/UdYWju3OuAviMMxQ0n7Nl3hKG54VF39h1haDavr74jDMXRL7u57wjDc8uUfM5vg3u+JEmSGrJ8SZIkNWT5kiRJasjyJUmS1JDlS5IkqSHLlyRJUkOWL0mSpIYsX5IkSQ1ZviRJkhqyfEmSJDVk+ZIkSWrI8iVJktSQ5UuSJKkhy5ckSVJDli9JkqSGLF+SJEkNWb4kSZIasnxJkiQ1ZPmSJElqyPIlSZLUkOVLkiSpIcuXJElSQ5YvSZKkhixfkiRJDVm+JEmSGlrWd4CtSbIGWAOwklU9p5EkSdp5Y73nq6rOraqTquqk5VnRdxxJkqSdNtblS5IkadqMtHwl+fUk/5Tk1FG+jyRJ0qQYWflKchzwI8AvACcmOXlU7yVJkjQpRrnnazVwVVXdBlwK7D7C95IkSZoIoyxfnwT2SXIR8IPAv47wvSRJkibCyKaaqKq7gNNG9f0lSZImkVc7SpIkNWT5kiRJasjyJUmS1JDlS5IkqSHLlyRJUkOWL0mSpIYsX5IkSQ1ZviRJkhqyfEmSJDVk+ZIkSWrI8iVJktSQ5UuSJKkhy5ckSVJDli9JkqSGLF+SJEkNWb4kSZIasnxJkiQ1tKzvAAtWUJs29Z1Cs2y+/fa+IwzPunV9Jxie79zQd4Kh2eem7/YdYSjuOPGwviMMzace+ea+IwzN4R99Rt8RhqOq7wRDUxs29h2hCfd8SZIkNWT5kiRJasjyJUmS1JDlS5IkqSHLlyRJUkOWL0mSpIYsX5IkSQ1ZviRJkhqyfEmSJDVk+ZIkSWrI8iVJktSQ5UuSJKkhy5ckSVJDli9JkqSGLF+SJEkNWb4kSZIasnxJkiQ1ZPmSJElqyPIlSZLUkOVLkiSpIcuXJElSQ5YvSZKkhixfkiRJDVm+JEmSGrJ8SZIkNbSs7wBbk2QNsAZgJat6TiNJkrTzxnrPV1WdW1UnVdVJy1nRdxxJkqSdNtblS5IkadpYviRJkhqyfEmSJDVk+ZIkSWrI8iVJktSQ5UuSJKkhy5ckSVJDli9JkqSGLF+SJEkNWb4kSZIasnxJkiQ1ZPmSJElqyPIlSZLUkOVLkiSpIcuXJElSQ5YvSZKkhixfkiRJDVm+JEmSGrJ8SZIkNWT5kiRJasjyJUmS1JDlS5IkqSHLlyRJUkOpqr4zLEiS7wBXNHirfYHrG7zPqE3LOMCxjKNpGQc4lnE1LWOZlnGAY9le96mq/eZbMTHlq5Uka6vqpL5z7KxpGQc4lnE0LeMAxzKupmUs0zIOcCzD5GFHSZKkhixfkiRJDVm+7u7cvgMMybSMAxzLOJqWcYBjGVfTMpZpGQc4lqHxnC9JkqSG3PMlSZLUkOVLkiSpIcuXJElSQ5YvSZKkhixfkiRJDf1/SzaFpzoN5ocAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"i am a little out of sorts today .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "9qYv1rYq1Lu5"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import pandas as pd\n",
    "\n",
    "input_sentences = load_data(os.path.join(data_dir, 'test.en'))\n",
    "target_sentences = load_data(os.path.join(data_dir, 'test.ja'))\n",
    "\n",
    "input_sentences = input_sentences[:TEST_SIZE_LIMIT]\n",
    "target_sentences = target_sentences[:TEST_SIZE_LIMIT]\n",
    "predicted_sentences = []\n",
    "\n",
    "for input_en in input_sentences:\n",
    "    predicted_ja, _, _ = evaluate(preprocess(input_en))\n",
    "    predicted_sentences.append(''.join(predicted_ja[:-1]))\n",
    "\n",
    "result_df = pd.DataFrame({'input_sentence': input_sentences,\n",
    "                          'target_sentence': target_sentences,\n",
    "                          'predicted_sentence': predicted_sentences})  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "16qn07BeMCJs"
   },
   "outputs": [],
   "source": [
    "bleu_scores = []\n",
    "for row in result_df.itertuples():\n",
    "    bleu_scores.append(\n",
    "        sentence_bleu(row.target_sentence, row.predicted_sentence,\n",
    "                      smoothing_function=SmoothingFunction().method4)\n",
    "    )\n",
    "result_df['bleu_score'] = bleu_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "bGnwSEkf9HlM",
    "outputId": "9ed3d5f6-4579-49b9-c4e1-eee0f13b19c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_sentence</th>\n",
       "      <th>target_sentence</th>\n",
       "      <th>predicted_sentence</th>\n",
       "      <th>bleu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>they finally acknowledged it as true .</td>\n",
       "      <td>彼 ら は つい に それ が 真実 だ と 認め た 。</td>\n",
       "      <td>彼 ら は それ を 言 っ た 。</td>\n",
       "      <td>0.269130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he didn 't care for swimming .</td>\n",
       "      <td>彼 は 水泳 が 得意 で は な かっ た 。</td>\n",
       "      <td>彼 は 泳ぎ を 入れ な かっ た 。</td>\n",
       "      <td>0.243904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he is no less kind than his sister .</td>\n",
       "      <td>彼 は お 姉 さん に 劣 ら ず 親切 だ 。</td>\n",
       "      <td>彼 は お 姉 さん と 話 す こと は 容易 で は な い 。</td>\n",
       "      <td>0.127277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you must be back before ten .</td>\n",
       "      <td>１０ 時 前 に 戻 ら な けれ ば な ら な い 。</td>\n",
       "      <td>10 時 まで に 戻 る な 。</td>\n",
       "      <td>0.268659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>break a leg .</td>\n",
       "      <td>成功 を 祈 る わ 。</td>\n",
       "      <td>い い な さ い 。</td>\n",
       "      <td>0.356676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>i 'm very sleepy now .</td>\n",
       "      <td>今 とても 眠 い 。</td>\n",
       "      <td>とても 疲れ で す 。</td>\n",
       "      <td>0.399584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>above the music , i could hear her crying .</td>\n",
       "      <td>音楽 が な っ て い る の に 彼女 の 鳴き声 が 聞こえ た 。</td>\n",
       "      <td>その 先生 の 話 を 知 ら せ ん だ と 思 っ た の で い る</td>\n",
       "      <td>0.107584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>we had the meeting in this room last friday .</td>\n",
       "      <td>先週 の 金曜 日 この 部屋 で 会合 が あ っ た 。</td>\n",
       "      <td>この 部屋 の 部屋 が あ り ま し た 。</td>\n",
       "      <td>0.196274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>who do you want to speak to ?</td>\n",
       "      <td>お 話 に な る 方 の お 名前 は 。</td>\n",
       "      <td>誰 が ため に 話 し た い で す か 。</td>\n",
       "      <td>0.160257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>his father eats there twice a week .</td>\n",
       "      <td>彼 の 父 は １ 週間 に ２ 回 そこ で 食べ る 。</td>\n",
       "      <td>彼 の お 父 さん に 戻 っ て い る 。</td>\n",
       "      <td>0.184321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    input_sentence  \\\n",
       "0           they finally acknowledged it as true .   \n",
       "1                   he didn 't care for swimming .   \n",
       "2             he is no less kind than his sister .   \n",
       "3                    you must be back before ten .   \n",
       "4                                    break a leg .   \n",
       "..                                             ...   \n",
       "295                         i 'm very sleepy now .   \n",
       "296    above the music , i could hear her crying .   \n",
       "297  we had the meeting in this room last friday .   \n",
       "298                  who do you want to speak to ?   \n",
       "299           his father eats there twice a week .   \n",
       "\n",
       "                           target_sentence  \\\n",
       "0            彼 ら は つい に それ が 真実 だ と 認め た 。   \n",
       "1                 彼 は 水泳 が 得意 で は な かっ た 。   \n",
       "2                彼 は お 姉 さん に 劣 ら ず 親切 だ 。   \n",
       "3            １０ 時 前 に 戻 ら な けれ ば な ら な い 。   \n",
       "4                             成功 を 祈 る わ 。   \n",
       "..                                     ...   \n",
       "295                            今 とても 眠 い 。   \n",
       "296  音楽 が な っ て い る の に 彼女 の 鳴き声 が 聞こえ た 。   \n",
       "297         先週 の 金曜 日 この 部屋 で 会合 が あ っ た 。   \n",
       "298                 お 話 に な る 方 の お 名前 は 。   \n",
       "299         彼 の 父 は １ 週間 に ２ 回 そこ で 食べ る 。   \n",
       "\n",
       "                        predicted_sentence  bleu_score  \n",
       "0                       彼 ら は それ を 言 っ た 。    0.269130  \n",
       "1                     彼 は 泳ぎ を 入れ な かっ た 。    0.243904  \n",
       "2       彼 は お 姉 さん と 話 す こと は 容易 で は な い 。    0.127277  \n",
       "3                        10 時 まで に 戻 る な 。    0.268659  \n",
       "4                              い い な さ い 。    0.356676  \n",
       "..                                     ...         ...  \n",
       "295                           とても 疲れ で す 。    0.399584  \n",
       "296  その 先生 の 話 を 知 ら せ ん だ と 思 っ た の で い る    0.107584  \n",
       "297               この 部屋 の 部屋 が あ り ま し た 。    0.196274  \n",
       "298               誰 が ため に 話 し た い で す か 。    0.160257  \n",
       "299               彼 の お 父 さん に 戻 っ て い る 。    0.184321  \n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9hQ_XKxIQ2W",
    "outputId": "3e30de47-f27d-48d9-9cb2-ddb562fbeb71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1926190246410859"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.bleu_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMgTzeT+AoMej2E7PB7H2z+",
   "collapsed_sections": [],
   "name": "seq2seq_with_attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
