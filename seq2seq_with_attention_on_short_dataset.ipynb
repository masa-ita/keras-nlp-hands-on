{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2859,
     "status": "ok",
     "timestamp": 1612533603852,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "QetvaJ27Tb6y",
    "outputId": "d5d13c9d-672a-497e-ebfc-b44b7e57965b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: japanize_matplotlib in /home/tensorflow/.local/lib/python3.6/site-packages (1.1.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from japanize_matplotlib) (3.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (7.2.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from matplotlib->japanize_matplotlib) (1.18.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->japanize_matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install japanize_matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_M-eDSyL-8E7",
    "outputId": "7f42f59e-e667-4f23-fa16-57d82dd3e4aa"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import get_file\n",
    "\n",
    "url = 'https://github.com/odashi/small_parallel_enja/archive/master.zip'\n",
    "\n",
    "zip_file_path = get_file('small_parallel_enja.zip', url, cache_subdir='small_parallel_enja', extract=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SsrpAmZ1BVFF",
    "outputId": "4f86b029-427d-4f1a-e5bc-89a286ec9b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 9076\n",
      "-rw-r--r-- 1 tensorflow tensorflow    1946 Feb 10 06:20 README.md\n",
      "-rw-r--r-- 1 tensorflow tensorflow   17054 Feb 10 06:20 dev.en\n",
      "-rw-r--r-- 1 tensorflow tensorflow   27781 Feb 10 06:20 dev.ja\n",
      "-rw-r--r-- 1 tensorflow tensorflow   17301 Feb 10 06:20 test.en\n",
      "-rw-r--r-- 1 tensorflow tensorflow   27793 Feb 10 06:20 test.ja\n",
      "-rw-r--r-- 1 tensorflow tensorflow 1701356 Feb 10 06:20 train.en\n",
      "-rw-r--r-- 1 tensorflow tensorflow  339768 Feb 10 06:20 train.en.000\n",
      "-rw-r--r-- 1 tensorflow tensorflow  340186 Feb 10 06:20 train.en.001\n",
      "-rw-r--r-- 1 tensorflow tensorflow  341174 Feb 10 06:20 train.en.002\n",
      "-rw-r--r-- 1 tensorflow tensorflow  339953 Feb 10 06:20 train.en.003\n",
      "-rw-r--r-- 1 tensorflow tensorflow  340275 Feb 10 06:20 train.en.004\n",
      "-rw-r--r-- 1 tensorflow tensorflow   30025 Feb 10 06:20 train.en.vocab.4k\n",
      "-rw-r--r-- 1 tensorflow tensorflow   51162 Feb 10 06:20 train.en.vocab.all\n",
      "-rw-r--r-- 1 tensorflow tensorflow 2784447 Feb 10 06:20 train.ja\n",
      "-rw-r--r-- 1 tensorflow tensorflow  556444 Feb 10 06:20 train.ja.000\n",
      "-rw-r--r-- 1 tensorflow tensorflow  555732 Feb 10 06:20 train.ja.001\n",
      "-rw-r--r-- 1 tensorflow tensorflow  557218 Feb 10 06:20 train.ja.002\n",
      "-rw-r--r-- 1 tensorflow tensorflow  557538 Feb 10 06:20 train.ja.003\n",
      "-rw-r--r-- 1 tensorflow tensorflow  557515 Feb 10 06:20 train.ja.004\n",
      "-rw-r--r-- 1 tensorflow tensorflow   31009 Feb 10 06:20 train.ja.vocab.4k\n",
      "-rw-r--r-- 1 tensorflow tensorflow   73669 Feb 10 06:20 train.ja.vocab.all\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = os.path.join(os.path.dirname(zip_file_path), 'small_parallel_enja-master')\n",
    "!ls -l $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "y3iF78mDMb1B"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def load_data(path):\n",
    "    tokenizer = Tokenizer(filters='')\n",
    "    \n",
    "    texts = []\n",
    "    for line in open(path, 'r'):\n",
    "        texts.append('<start> ' + line.strip() + ' <end>')\n",
    "    \n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    return tokenizer.texts_to_sequences(texts), tokenizer\n",
    "\n",
    "en, inp_lang = load_data(os.path.join(data_dir, 'train.en'))\n",
    "ja, targ_lang = load_data(os.path.join(data_dir, 'train.ja'))\n",
    "\n",
    "vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "vocab_tar_size = len(targ_lang.word_index) + 1\n",
    "\n",
    "train_en, test_en, train_ja, test_ja = train_test_split(en, ja, test_size=0.1, random_state=36)\n",
    "\n",
    "input_tensor_train = pad_sequences(train_en, padding='post')\n",
    "target_tensor_train = pad_sequences(train_ja, padding='post')\n",
    "input_tensor_val = pad_sequences(test_en, padding='post')\n",
    "target_tensor_val = pad_sequences(test_ja, padding='post')\n",
    "\n",
    "max_length_inp = len(input_tensor_train[0])\n",
    "max_length_targ = len(target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 20969,
     "status": "ok",
     "timestamp": 1612533622233,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "cfxSreRrXvw4"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20946,
     "status": "ok",
     "timestamp": 1612533622233,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "qBMUz4Q9Xxe7",
    "outputId": "dae0dde9-4b87-4f04-f9c0-83406ba9bfbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "5 ----> i\n",
      "512 ----> walked\n",
      "12 ----> in\n",
      "4 ----> the\n",
      "2801 ----> woods\n",
      "51 ----> by\n",
      "410 ----> myself\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "17 ----> 私\n",
      "4 ----> は\n",
      "265 ----> 一人\n",
      "11 ----> で\n",
      "1571 ----> 森\n",
      "8 ----> を\n",
      "198 ----> 歩\n",
      "5 ----> い\n",
      "7 ----> た\n",
      "3 ----> 。\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 21908,
     "status": "ok",
     "timestamp": 1612533623222,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "ZDYSOGLzYbP8"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train) // BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21906,
     "status": "ok",
     "timestamp": 1612533623225,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "OkZvi19gYp03",
    "outputId": "accb9126-2ff7-4c96-9d02-8cd62073cddd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 18]), TensorShape([64, 18]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 21881,
     "status": "ok",
     "timestamp": 1612533623226,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "YYHYgc4hYwly"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23528,
     "status": "ok",
     "timestamp": 1612533624879,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "v5fs_ECmZP8N",
    "outputId": "b516d329-0f71-4394-b486-d79e4a389450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 18, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# サンプル入力\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 23503,
     "status": "ok",
     "timestamp": 1612533624880,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "fRy4fGRXZU9P"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # スコアを計算するためにこのように加算を実行する\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # スコアを self.V に適用するために最後の軸は 1 となる\n",
    "        # self.V に適用する前のテンソルの shape は  (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "                      self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights の shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector の合計後の shape == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23787,
     "status": "ok",
     "timestamp": 1612533625170,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "QaX0KziyZoN5",
    "outputId": "bbb96965-3606-43a7-ee8a-11950147e010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 23763,
     "status": "ok",
     "timestamp": 1612533625171,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "yzuNjW0lZs1y"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # アテンションのため\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output の shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # 埋め込み層を通過したあとの x の shape  == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # 結合後の x の shape == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # 結合したベクトルを GRU 層に渡す\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23758,
     "status": "ok",
     "timestamp": 1612533625171,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "yP8fSgqDZ9Ci",
    "outputId": "28bed07a-7565-40d5-a52f-f6dc025ebf43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 8777)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 23733,
     "status": "ok",
     "timestamp": 1612533625172,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "xOmW4oGQaBuJ"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                             from_logits=True, reduction='none')\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 23729,
     "status": "ok",
     "timestamp": 1612533625173,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "j1xOnT6oaOCY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 23725,
     "status": "ok",
     "timestamp": 1612533625174,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "DaknH7tgaTEt"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher Forcing - 正解値を次の入力として供給\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # Teacher Forcing を使用\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1986767,
     "status": "ok",
     "timestamp": 1612535588222,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "5bNwa8eCa0Ru",
    "outputId": "d3629362-c291-47dc-8ec8-c49648190c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 6.2661\n",
      "Epoch 1 Batch 100 Loss 2.8958\n",
      "Epoch 1 Batch 200 Loss 2.5642\n",
      "Epoch 1 Batch 300 Loss 2.3151\n",
      "Epoch 1 Batch 400 Loss 2.1025\n",
      "Epoch 1 Batch 500 Loss 2.1533\n",
      "Epoch 1 Batch 600 Loss 2.0071\n",
      "Epoch 1 Batch 700 Loss 2.0877\n",
      "Epoch 1 Loss 2.4364\n",
      "Time taken for 1 epoch 119.46129512786865 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.9589\n",
      "Epoch 2 Batch 100 Loss 1.9013\n",
      "Epoch 2 Batch 200 Loss 1.8852\n",
      "Epoch 2 Batch 300 Loss 1.7491\n",
      "Epoch 2 Batch 400 Loss 1.6551\n",
      "Epoch 2 Batch 500 Loss 1.7680\n",
      "Epoch 2 Batch 600 Loss 1.5845\n",
      "Epoch 2 Batch 700 Loss 1.5786\n",
      "Epoch 2 Loss 1.7657\n",
      "Time taken for 1 epoch 101.2643392086029 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.5686\n",
      "Epoch 3 Batch 100 Loss 1.4646\n",
      "Epoch 3 Batch 200 Loss 1.4449\n",
      "Epoch 3 Batch 300 Loss 1.3569\n",
      "Epoch 3 Batch 400 Loss 1.4870\n",
      "Epoch 3 Batch 500 Loss 1.3600\n",
      "Epoch 3 Batch 600 Loss 1.3369\n",
      "Epoch 3 Batch 700 Loss 1.3782\n",
      "Epoch 3 Loss 1.3719\n",
      "Time taken for 1 epoch 101.10649156570435 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.1379\n",
      "Epoch 4 Batch 100 Loss 1.1235\n",
      "Epoch 4 Batch 200 Loss 1.0404\n",
      "Epoch 4 Batch 300 Loss 1.1677\n",
      "Epoch 4 Batch 400 Loss 1.0946\n",
      "Epoch 4 Batch 500 Loss 1.0238\n",
      "Epoch 4 Batch 600 Loss 0.9684\n",
      "Epoch 4 Batch 700 Loss 1.0157\n",
      "Epoch 4 Loss 1.0692\n",
      "Time taken for 1 epoch 101.42417168617249 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.9150\n",
      "Epoch 5 Batch 100 Loss 0.9581\n",
      "Epoch 5 Batch 200 Loss 1.0341\n",
      "Epoch 5 Batch 300 Loss 0.9779\n",
      "Epoch 5 Batch 400 Loss 0.8273\n",
      "Epoch 5 Batch 500 Loss 1.0310\n",
      "Epoch 5 Batch 600 Loss 0.8896\n",
      "Epoch 5 Batch 700 Loss 0.8357\n",
      "Epoch 5 Loss 0.8574\n",
      "Time taken for 1 epoch 101.28867244720459 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.6819\n",
      "Epoch 6 Batch 100 Loss 0.7344\n",
      "Epoch 6 Batch 200 Loss 0.7262\n",
      "Epoch 6 Batch 300 Loss 0.7723\n",
      "Epoch 6 Batch 400 Loss 0.6823\n",
      "Epoch 6 Batch 500 Loss 0.6144\n",
      "Epoch 6 Batch 600 Loss 0.6513\n",
      "Epoch 6 Batch 700 Loss 0.7966\n",
      "Epoch 6 Loss 0.6946\n",
      "Time taken for 1 epoch 101.85958170890808 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.5877\n",
      "Epoch 7 Batch 100 Loss 0.5254\n",
      "Epoch 7 Batch 200 Loss 0.5673\n",
      "Epoch 7 Batch 300 Loss 0.5223\n",
      "Epoch 7 Batch 400 Loss 0.4965\n",
      "Epoch 7 Batch 500 Loss 0.6146\n",
      "Epoch 7 Batch 600 Loss 0.5728\n",
      "Epoch 7 Batch 700 Loss 0.5930\n",
      "Epoch 7 Loss 0.5650\n",
      "Time taken for 1 epoch 101.22624278068542 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.4039\n",
      "Epoch 8 Batch 100 Loss 0.4910\n",
      "Epoch 8 Batch 200 Loss 0.4776\n",
      "Epoch 8 Batch 300 Loss 0.4718\n",
      "Epoch 8 Batch 400 Loss 0.5281\n",
      "Epoch 8 Batch 500 Loss 0.5177\n",
      "Epoch 8 Batch 600 Loss 0.4822\n",
      "Epoch 8 Batch 700 Loss 0.5278\n",
      "Epoch 8 Loss 0.4582\n",
      "Time taken for 1 epoch 101.77358627319336 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.3167\n",
      "Epoch 9 Batch 100 Loss 0.3484\n",
      "Epoch 9 Batch 200 Loss 0.3563\n",
      "Epoch 9 Batch 300 Loss 0.3600\n",
      "Epoch 9 Batch 400 Loss 0.4413\n",
      "Epoch 9 Batch 500 Loss 0.4219\n",
      "Epoch 9 Batch 600 Loss 0.3879\n",
      "Epoch 9 Batch 700 Loss 0.4161\n",
      "Epoch 9 Loss 0.3719\n",
      "Time taken for 1 epoch 100.36781787872314 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.2955\n",
      "Epoch 10 Batch 100 Loss 0.2704\n",
      "Epoch 10 Batch 200 Loss 0.2944\n",
      "Epoch 10 Batch 300 Loss 0.2490\n",
      "Epoch 10 Batch 400 Loss 0.2635\n",
      "Epoch 10 Batch 500 Loss 0.3229\n",
      "Epoch 10 Batch 600 Loss 0.3610\n",
      "Epoch 10 Batch 700 Loss 0.3067\n",
      "Epoch 10 Loss 0.3011\n",
      "Time taken for 1 epoch 101.34643316268921 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.1879\n",
      "Epoch 11 Batch 100 Loss 0.2164\n",
      "Epoch 11 Batch 200 Loss 0.2229\n",
      "Epoch 11 Batch 300 Loss 0.2781\n",
      "Epoch 11 Batch 400 Loss 0.2561\n",
      "Epoch 11 Batch 500 Loss 0.2614\n",
      "Epoch 11 Batch 600 Loss 0.2881\n",
      "Epoch 11 Batch 700 Loss 0.3259\n",
      "Epoch 11 Loss 0.2419\n",
      "Time taken for 1 epoch 100.85775136947632 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.1898\n",
      "Epoch 12 Batch 100 Loss 0.1535\n",
      "Epoch 12 Batch 200 Loss 0.1476\n",
      "Epoch 12 Batch 300 Loss 0.2088\n",
      "Epoch 12 Batch 400 Loss 0.1922\n",
      "Epoch 12 Batch 500 Loss 0.2193\n",
      "Epoch 12 Batch 600 Loss 0.2243\n",
      "Epoch 12 Batch 700 Loss 0.2249\n",
      "Epoch 12 Loss 0.1984\n",
      "Time taken for 1 epoch 100.83113288879395 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.1465\n",
      "Epoch 13 Batch 100 Loss 0.1180\n",
      "Epoch 13 Batch 200 Loss 0.1560\n",
      "Epoch 13 Batch 300 Loss 0.1956\n",
      "Epoch 13 Batch 400 Loss 0.2275\n",
      "Epoch 13 Batch 500 Loss 0.1833\n",
      "Epoch 13 Batch 600 Loss 0.1801\n",
      "Epoch 13 Batch 700 Loss 0.2053\n",
      "Epoch 13 Loss 0.1645\n",
      "Time taken for 1 epoch 100.43343997001648 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.1147\n",
      "Epoch 14 Batch 100 Loss 0.1290\n",
      "Epoch 14 Batch 200 Loss 0.1035\n",
      "Epoch 14 Batch 300 Loss 0.1492\n",
      "Epoch 14 Batch 400 Loss 0.1621\n",
      "Epoch 14 Batch 500 Loss 0.1273\n",
      "Epoch 14 Batch 600 Loss 0.1496\n",
      "Epoch 14 Batch 700 Loss 0.1626\n",
      "Epoch 14 Loss 0.1403\n",
      "Time taken for 1 epoch 101.55529737472534 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.1074\n",
      "Epoch 15 Batch 100 Loss 0.1077\n",
      "Epoch 15 Batch 200 Loss 0.1147\n",
      "Epoch 15 Batch 300 Loss 0.1408\n",
      "Epoch 15 Batch 400 Loss 0.1292\n",
      "Epoch 15 Batch 500 Loss 0.1667\n",
      "Epoch 15 Batch 600 Loss 0.1065\n",
      "Epoch 15 Batch 700 Loss 0.1153\n",
      "Epoch 15 Loss 0.1311\n",
      "Time taken for 1 epoch 100.74411034584045 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.1123\n",
      "Epoch 16 Batch 100 Loss 0.0954\n",
      "Epoch 16 Batch 200 Loss 0.1185\n",
      "Epoch 16 Batch 300 Loss 0.1162\n",
      "Epoch 16 Batch 400 Loss 0.1312\n",
      "Epoch 16 Batch 500 Loss 0.1245\n",
      "Epoch 16 Batch 600 Loss 0.1293\n",
      "Epoch 16 Batch 700 Loss 0.1349\n",
      "Epoch 16 Loss 0.1129\n",
      "Time taken for 1 epoch 101.34197902679443 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0756\n",
      "Epoch 17 Batch 100 Loss 0.0934\n",
      "Epoch 17 Batch 200 Loss 0.0892\n",
      "Epoch 17 Batch 300 Loss 0.0936\n",
      "Epoch 17 Batch 400 Loss 0.1305\n",
      "Epoch 17 Batch 500 Loss 0.1366\n",
      "Epoch 17 Batch 600 Loss 0.0893\n",
      "Epoch 17 Batch 700 Loss 0.1233\n",
      "Epoch 17 Loss 0.1032\n",
      "Time taken for 1 epoch 101.13745188713074 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0675\n",
      "Epoch 18 Batch 100 Loss 0.1006\n",
      "Epoch 18 Batch 200 Loss 0.0953\n",
      "Epoch 18 Batch 300 Loss 0.1098\n",
      "Epoch 18 Batch 400 Loss 0.1071\n",
      "Epoch 18 Batch 500 Loss 0.1064\n",
      "Epoch 18 Batch 600 Loss 0.0924\n",
      "Epoch 18 Batch 700 Loss 0.1095\n",
      "Epoch 18 Loss 0.0994\n",
      "Time taken for 1 epoch 100.86759924888611 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0715\n",
      "Epoch 19 Batch 100 Loss 0.0897\n",
      "Epoch 19 Batch 200 Loss 0.0720\n",
      "Epoch 19 Batch 300 Loss 0.0726\n",
      "Epoch 19 Batch 400 Loss 0.1035\n",
      "Epoch 19 Batch 500 Loss 0.1021\n",
      "Epoch 19 Batch 600 Loss 0.1144\n",
      "Epoch 19 Batch 700 Loss 0.1399\n",
      "Epoch 19 Loss 0.0964\n",
      "Time taken for 1 epoch 101.2869782447815 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.1100\n",
      "Epoch 20 Batch 100 Loss 0.0659\n",
      "Epoch 20 Batch 200 Loss 0.0678\n",
      "Epoch 20 Batch 300 Loss 0.0954\n",
      "Epoch 20 Batch 400 Loss 0.0945\n",
      "Epoch 20 Batch 500 Loss 0.0869\n",
      "Epoch 20 Batch 600 Loss 0.0873\n",
      "Epoch 20 Batch 700 Loss 0.1572\n",
      "Epoch 20 Loss 0.0909\n",
      "Time taken for 1 epoch 101.6501579284668 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "              print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "    # 2 エポックごとにモデル（のチェックポイント）を保存\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs):\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    predicted_seq = []\n",
    "    \n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # 後ほどプロットするためにアテンションの重みを保存\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        predicted_seq.append(predicted_id)\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return predicted_seq\n",
    "\n",
    "        # 予測された ID がモデルに戻される\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return predicted_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 1986744,
     "status": "ok",
     "timestamp": 1612535588224,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "H6kO2HY0bEn0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # 後ほどプロットするためにアテンションの重みを保存\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # 予測された ID がモデルに戻される\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 1986740,
     "status": "ok",
     "timestamp": 1612535588225,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "tnwoWfkYfwBZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import japanize_matplotlib\n",
    "\n",
    "# アテンションの重みをプロットする関数\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 1986735,
     "status": "ok",
     "timestamp": 1612535588226,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "q-zIxy2Zf3vw"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1986983,
     "status": "ok",
     "timestamp": 1612535588478,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "mIbzsxI-f8Z9",
    "outputId": "59c2afce-8f46-45af-c773-e8be712eb93a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f26b4296b38>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_dir の中の最後のチェックポイントを復元\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "executionInfo": {
     "elapsed": 1987264,
     "status": "ok",
     "timestamp": 1612535588788,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "aX4evgWVf9xa",
    "outputId": "831a9943-b7d0-4458-c854-0203c14ea490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> i can 't hear you . <end>\n",
      "Predicted translation: あなた の おっしゃ る こと が 聞こえ ま せ ん 。 <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"<start> i can 't hear you . <end>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9qYv1rYq1Lu5"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import pandas as pd\n",
    "\n",
    "input_sentences = []\n",
    "target_sentences = []\n",
    "predicted_sentences = []\n",
    "\n",
    "for i, input_en in enumerate(input_tensor_val):\n",
    "    predicted_ja = predict([input_en])\n",
    "    tokens_input = [inp_lang.index_word[id] for id in input_en if id > 2]\n",
    "    tokens_target = [targ_lang.index_word[id] for id in target_tensor_val[i] if id > 2]\n",
    "    tokens_predicted = [targ_lang.index_word[id] for id in predicted_ja if id > 2]\n",
    "    input_sentences.append(' '.join(tokens_input))\n",
    "    target_sentences.append(''.join(tokens_target))\n",
    "    predicted_sentences.append(''.join(tokens_predicted))\n",
    "\n",
    "result_df = pd.DataFrame({'input_sentence': input_sentences,\n",
    "                          'target_sentence': target_sentences,\n",
    "                          'predicted_sentence': predicted_sentences})  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "16qn07BeMCJs"
   },
   "outputs": [],
   "source": [
    "bleu_scores = []\n",
    "for row in result_df.itertuples():\n",
    "    bleu_scores.append(\n",
    "        sentence_bleu(row.target_sentence, row.predicted_sentence,\n",
    "                      smoothing_function=SmoothingFunction().method4)\n",
    "    )\n",
    "result_df['bleu_score'] = bleu_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "bGnwSEkf9HlM",
    "outputId": "9ed3d5f6-4579-49b9-c4e1-eee0f13b19c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_sentence</th>\n",
       "      <th>target_sentence</th>\n",
       "      <th>predicted_sentence</th>\n",
       "      <th>bleu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i was wrong .</td>\n",
       "      <td>私が間違っていました。</td>\n",
       "      <td>私は間違っていました。</td>\n",
       "      <td>0.533355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>she is going to learn how to drive .</td>\n",
       "      <td>彼女は近く、運転を習うつもりでいます。</td>\n",
       "      <td>彼女は車を学ぶ気が立っています。</td>\n",
       "      <td>0.311208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i am fond of skiing .</td>\n",
       "      <td>私はスキーが好きだ。</td>\n",
       "      <td>スキーが好き。</td>\n",
       "      <td>0.932776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i will start working on july the first .</td>\n",
       "      <td>７月１日から仕事を始めます。</td>\n",
       "      <td>私は一番のところを始めます。</td>\n",
       "      <td>0.342626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ken took the examination with confidence .</td>\n",
       "      <td>ケンは自信をもって試験を受けた。</td>\n",
       "      <td>ケンは試験を受けた。</td>\n",
       "      <td>0.606993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>either you or i am in the wrong .</td>\n",
       "      <td>あなたか私かどちらかが間違っている。</td>\n",
       "      <td>君か僕の意見が間違っている。</td>\n",
       "      <td>0.379178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>you 've got it in one . that 's right .</td>\n",
       "      <td>君はすぐに分かったんだね。そのとおりだよ。</td>\n",
       "      <td>それはそれであると思ったのだから。</td>\n",
       "      <td>0.297320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>all you have to do is believe me .</td>\n",
       "      <td>君は僕を信じさえすれば良い。</td>\n",
       "      <td>君は私を信じさえすればよい。</td>\n",
       "      <td>0.407453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>i was embarrassed by what she said .</td>\n",
       "      <td>彼女の言葉を聞いてどぎまぎした。</td>\n",
       "      <td>僕は彼女の言って彼女の言ってしまったことに困惑</td>\n",
       "      <td>0.200410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>i can 't hear you .</td>\n",
       "      <td>聞こえませんよ。</td>\n",
       "      <td>あなたのおっしゃることが聞こえません。</td>\n",
       "      <td>0.243706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  input_sentence        target_sentence  \\\n",
       "0                                  i was wrong .            私が間違っていました。   \n",
       "1           she is going to learn how to drive .    彼女は近く、運転を習うつもりでいます。   \n",
       "2                          i am fond of skiing .             私はスキーが好きだ。   \n",
       "3       i will start working on july the first .         ７月１日から仕事を始めます。   \n",
       "4     ken took the examination with confidence .       ケンは自信をもって試験を受けた。   \n",
       "...                                          ...                    ...   \n",
       "4995           either you or i am in the wrong .     あなたか私かどちらかが間違っている。   \n",
       "4996     you 've got it in one . that 's right .  君はすぐに分かったんだね。そのとおりだよ。   \n",
       "4997          all you have to do is believe me .         君は僕を信じさえすれば良い。   \n",
       "4998        i was embarrassed by what she said .       彼女の言葉を聞いてどぎまぎした。   \n",
       "4999                         i can 't hear you .               聞こえませんよ。   \n",
       "\n",
       "           predicted_sentence  bleu_score  \n",
       "0                 私は間違っていました。    0.533355  \n",
       "1            彼女は車を学ぶ気が立っています。    0.311208  \n",
       "2                     スキーが好き。    0.932776  \n",
       "3              私は一番のところを始めます。    0.342626  \n",
       "4                  ケンは試験を受けた。    0.606993  \n",
       "...                       ...         ...  \n",
       "4995           君か僕の意見が間違っている。    0.379178  \n",
       "4996        それはそれであると思ったのだから。    0.297320  \n",
       "4997           君は私を信じさえすればよい。    0.407453  \n",
       "4998  僕は彼女の言って彼女の言ってしまったことに困惑    0.200410  \n",
       "4999      あなたのおっしゃることが聞こえません。    0.243706  \n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9hQ_XKxIQ2W",
    "outputId": "3e30de47-f27d-48d9-9cb2-ddb562fbeb71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4239057127925631"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.bleu_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1987240,
     "status": "ok",
     "timestamp": 1612535588789,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "9qYv1rYq1Lu5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMgTzeT+AoMej2E7PB7H2z+",
   "collapsed_sections": [],
   "name": "seq2seq_with_attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
