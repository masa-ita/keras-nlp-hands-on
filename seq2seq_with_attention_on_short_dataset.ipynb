{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention付きSeq2Seqを使った機械翻訳"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BSNアイネットの社内LAN用の設定\n",
    "プロキシ配下でtf.keras.utils.get_file()がSSL証明書をロードできないエラーを回避するため。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for BSN I-Net local only\n",
    "import requests\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    # Legacy Python that doesn't verify HTTPS certificates by default\n",
    "    pass\n",
    "else:\n",
    "    # Handle target environment that doesn't support HTTPS verification\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matplotlibで日本語を表示するためのライブラリインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2859,
     "status": "ok",
     "timestamp": 1612533603852,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "QetvaJ27Tb6y",
    "outputId": "d5d13c9d-672a-497e-ebfc-b44b7e57965b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting japanize_matplotlib\n",
      "  Downloading japanize-matplotlib-1.1.3.tar.gz (4.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.1 MB 521 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /Users/itagaki/py_venvs/tf2/lib/python3.7/site-packages (from japanize_matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/itagaki/py_venvs/tf2/lib/python3.7/site-packages (from matplotlib->japanize_matplotlib) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /Users/itagaki/py_venvs/tf2/lib/python3.7/site-packages (from matplotlib->japanize_matplotlib) (1.19.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/itagaki/py_venvs/tf2/lib/python3.7/site-packages (from matplotlib->japanize_matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/itagaki/py_venvs/tf2/lib/python3.7/site-packages (from matplotlib->japanize_matplotlib) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/itagaki/py_venvs/tf2/lib/python3.7/site-packages (from matplotlib->japanize_matplotlib) (2.4.5)\n",
      "Requirement already satisfied: six in /Users/itagaki/py_venvs/tf2/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->japanize_matplotlib) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /Users/itagaki/py_venvs/tf2/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->japanize_matplotlib) (53.0.0)\n",
      "Building wheels for collected packages: japanize-matplotlib\n",
      "  Building wheel for japanize-matplotlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for japanize-matplotlib: filename=japanize_matplotlib-1.1.3-py3-none-any.whl size=4120274 sha256=da1a426a918e64a2ace6d1e68f8298b6c7e4f619e5179e96975ccfcbc9a9b9f8\n",
      "  Stored in directory: /Users/itagaki/Library/Caches/pip/wheels/83/97/6b/e9e0cde099cc40f972b8dd23367308f7705ae06cd6d4714658\n",
      "Successfully built japanize-matplotlib\n",
      "Installing collected packages: japanize-matplotlib\n",
      "Successfully installed japanize-matplotlib-1.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install japanize_matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import japanize_matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import get_file\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 英日翻訳データセットのダウンロード"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この演習では、小田悠介氏（現：LegalForce Research チーフリサーチャー）が公開している \"small_parallel_enja\" を使用します。  \n",
    "このデータセットは、日英対訳コーパスとして知られている[TANAKA corpus](http://www.edrdg.org/wiki/index.php/Tanaka_Corpus)から、文長が4単語から16単語までの短い文を抽出し、トークナイザ（英語:Stanford Tokenizer/日本語:KyTea）でトークナイズしたデータセットです。  \n",
    "下記のコードでは、`tf.keras.utils.get_file()`を使ってGitHubからZIPファイルをダウンロードして展開し、展開されたディレクトリの内容を確認しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SsrpAmZ1BVFF",
    "outputId": "4f86b029-427d-4f1a-e5bc-89a286ec9b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 20784\n",
      "-rw-r--r--  1 itagaki  staff     1946  2 12 16:00 README.md\n",
      "-rw-r--r--  1 itagaki  staff    17054  2 12 16:00 dev.en\n",
      "-rw-r--r--  1 itagaki  staff    27781  2 12 16:00 dev.ja\n",
      "-rw-r--r--  1 itagaki  staff    17301  2 12 16:00 test.en\n",
      "-rw-r--r--  1 itagaki  staff    27793  2 12 16:00 test.ja\n",
      "-rw-r--r--  1 itagaki  staff  1701356  2 12 16:00 train.en\n",
      "-rw-r--r--  1 itagaki  staff   339768  2 12 16:00 train.en.000\n",
      "-rw-r--r--  1 itagaki  staff   340186  2 12 16:00 train.en.001\n",
      "-rw-r--r--  1 itagaki  staff   341174  2 12 16:00 train.en.002\n",
      "-rw-r--r--  1 itagaki  staff   339953  2 12 16:00 train.en.003\n",
      "-rw-r--r--  1 itagaki  staff   340275  2 12 16:00 train.en.004\n",
      "-rw-r--r--  1 itagaki  staff    30025  2 12 16:00 train.en.vocab.4k\n",
      "-rw-r--r--  1 itagaki  staff    51162  2 12 16:00 train.en.vocab.all\n",
      "-rw-r--r--  1 itagaki  staff  2784447  2 12 16:00 train.ja\n",
      "-rw-r--r--  1 itagaki  staff   556444  2 12 16:00 train.ja.000\n",
      "-rw-r--r--  1 itagaki  staff   555732  2 12 16:00 train.ja.001\n",
      "-rw-r--r--  1 itagaki  staff   557218  2 12 16:00 train.ja.002\n",
      "-rw-r--r--  1 itagaki  staff   557538  2 12 16:00 train.ja.003\n",
      "-rw-r--r--  1 itagaki  staff   557515  2 12 16:00 train.ja.004\n",
      "-rw-r--r--  1 itagaki  staff    31009  2 12 16:00 train.ja.vocab.4k\n",
      "-rw-r--r--  1 itagaki  staff    73669  2 12 16:00 train.ja.vocab.all\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://github.com/odashi/small_parallel_enja/archive/master.zip'\n",
    "\n",
    "zip_file_path = get_file('small_parallel_enja.zip', URL, cache_subdir='small_parallel_enja', extract=True) \n",
    "\n",
    "data_dir = os.path.join(os.path.dirname(zip_file_path), 'small_parallel_enja-master')\n",
    "\n",
    "!ls -l $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練用データの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "small_parallel_enjaデータセットでは、訓練用のデータが50,000ペア含まれていますが、ここでは学習にかかる時間を短縮するため、最初の30000件のみを使用します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "y3iF78mDMb1B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"i can 't tell who will arrive first .\", 'many animals have been destroyed by men .', \"i 'm in the tennis club .\"]\n",
      "['誰 が 一番 に 着 く か 私 に は 分か り ま せ ん 。', '多く の 動物 が 人間 に よ っ て 滅ぼ さ れ た 。', '私 は テニス 部員 で す 。']\n"
     ]
    }
   ],
   "source": [
    "# 訓練時間節約のためデータの一部のみ使用する\n",
    "TRAIN_SIZE_LIMIT = 30000\n",
    "\n",
    "def load_data(path):\n",
    "    texts = []\n",
    "    for line in open(path, 'r'):\n",
    "        texts.append(line.strip()) # 改行コードなどを除去\n",
    "    return texts\n",
    "  \n",
    "\n",
    "train_en = load_data(os.path.join(data_dir, 'train.en'))\n",
    "train_ja = load_data(os.path.join(data_dir, 'train.ja'))\n",
    "\n",
    "train_en = train_en[:TRAIN_SIZE_LIMIT]\n",
    "train_ja = train_ja[:TRAIN_SIZE_LIMIT]\n",
    "\n",
    "print(train_en[:3])\n",
    "print(train_ja[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの前処理を行います。今回のデータはトークナイズ済みであるため、ユニコードの表現のブレを正規化する処理と、文頭及び文末にそれぞれ目印となるトークンを追加する処理のみを行なっています。データや目的によっては、記号やHTMLタグなどの除去や大文字の小文字への変換などを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = unicodedata.normalize('NFKC', text) # ユニコード正規化\n",
    "    text = '<start> ' + text + ' <end>'        # 文頭と文末を表すトークンを追加\n",
    "    return text\n",
    "\n",
    "train_input = [preprocess(s) for s in train_en]\n",
    "train_target = [preprocess(s) for s in train_ja]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 入力および出力の最大長"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回のデータセットでは、英語、日本語とも最大長は16語、これに<start>, <end>を加えた18が最大長です。 　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "y3iF78mDMb1B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input max length: 18\n",
      "target max length: 18\n"
     ]
    }
   ],
   "source": [
    "input_lengths = [len(s.split(' ')) for s in train_input]\n",
    "target_lengths = [len(s.split(' ')) for s in train_target]\n",
    "\n",
    "max_length_inp = max(input_lengths)\n",
    "max_length_targ = max(target_lengths)\n",
    "\n",
    "print('input max length:', max_length_inp)\n",
    "print('target max length:', max_length_targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トークンのベクトル化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トークンを機械学習モデルで扱えるようにベクトル化します。  \n",
    "TensorFlowで使えるベクトル化モジュールには、`tf.keras.preprocessing.text.Tokenizer`などいくつかありますが、ここでは新しく開発された`tf.keras.layers.experimental.preprocessing.TextVectorization`を使用します。このクラスは、レイヤとして実装されているため、関数として使用する他に、モデルに組み込んで実行することも可能です。また、出力も今回使用するトークンを整数値にする'int'モードの他に、テキスト全体をマルチホットベクトル化する'binary'モード、単語の出現回数のベクトルにする'count'モード、TF-IDFベクトル化する'tf-idf'モードが使える他、出力の長さを揃えてパディングを行う機能も備えています。\n",
    "\n",
    "TextVectorization()では、ボキャブラリーをファイルから直接読み込ませることもできますが、今回は訓練用データをつかって語彙の抽出を行なっています。\n",
    "\n",
    "ベクトル化したデータは、tf.data.Datasetに変換し、input（英語）とtarget（日本語）のペアを構成するtrain_dsデータセットに加工しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vectorizer = TextVectorization(max_tokens=20000,\n",
    "                                  standardize=None,\n",
    "                                  output_mode='int',\n",
    "                                  output_sequence_length=max_length_inp)\n",
    "\n",
    "ja_vectorizer = TextVectorization(max_tokens=20000,\n",
    "                                  standardize=None,\n",
    "                                  output_mode='int',\n",
    "                                  output_sequence_length=max_length_targ)\n",
    "\n",
    "en_vectorizer.adapt(train_input)\n",
    "ja_vectorizer.adapt(train_target)\n",
    "\n",
    "train_input_ds = tf.data.Dataset.from_tensor_slices(en_vectorizer(train_input))\n",
    "train_target_ds = tf.data.Dataset.from_tensor_slices(ja_vectorizer(train_target))\n",
    "\n",
    "train_ds = tf.data.Dataset.zip((train_input_ds, train_target_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ボキャブラリの抽出と語彙数の計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TextVectorizationでは、パディングに使われる0も空文字列としてボキャブラリに含まれています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "y3iF78mDMb1B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', '<start>', '<end>', '.', 'the', 'i', 'to', 'you', 'is']\n",
      "['', '[UNK]', '<start>', '<end>', '。', 'は', 'い', 'に', 'た', 'を']\n"
     ]
    }
   ],
   "source": [
    "en_vocab = en_vectorizer.get_vocabulary()\n",
    "ja_vocab = ja_vectorizer.get_vocabulary()\n",
    "vocab_inp_size = len(en_vocab)\n",
    "vocab_tar_size = len(ja_vocab)\n",
    "\n",
    "print(en_vocab[:10])\n",
    "print(ja_vocab[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## サンプルデータの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 20969,
     "status": "ok",
     "timestamp": 1612533622233,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "cfxSreRrXvw4"
   },
   "outputs": [],
   "source": [
    "def convert(vocab, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, vocab[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "en, ja = next(iter(train_ds)) # train_dsから最初のデータを取り出す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20946,
     "status": "ok",
     "timestamp": 1612533622233,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "qBMUz4Q9Xxe7",
    "outputId": "dae0dde9-4b87-4f04-f9c0-83406ba9bfbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "2 ----> <start>\n",
      "6 ----> i\n",
      "41 ----> can\n",
      "22 ----> 't\n",
      "149 ----> tell\n",
      "136 ----> who\n",
      "29 ----> will\n",
      "709 ----> arrive\n",
      "231 ----> first\n",
      "4 ----> .\n",
      "3 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "2 ----> <start>\n",
      "92 ----> 誰\n",
      "14 ----> が\n",
      "239 ----> 一番\n",
      "7 ----> に\n",
      "161 ----> 着\n",
      "29 ----> く\n",
      "22 ----> か\n",
      "18 ----> 私\n",
      "7 ----> に\n",
      "5 ----> は\n",
      "290 ----> 分か\n",
      "39 ----> り\n",
      "21 ----> ま\n",
      "40 ----> せ\n",
      "30 ----> ん\n",
      "4 ----> 。\n",
      "3 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(en_vocab, en.numpy())\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(ja_vocab, ja.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention付きのSeq2Seqモデルは下図のような構造を持っています。\n",
    "\n",
    "リカレントニューラルネットワーク（RNN）を使ったEncoder/Decoderモデルですが、単純なSeq2SeqモデルがDecoderの出力のみを使って次の単語を予測するのに対して、Encoderのすべての時点の状態情報と出力を使い、これにデコーダーの現在の状態を組み合わせて重み付けを行ってコンテキストベクトルを生成します。このコンテキストベクトルとデコーダーの現時点の状態を組み合わせてアテンションベクトルを計算し、このベクトルから次の単語を推定します。\n",
    "\n",
    "1階層のアテンション付きRNNの場合、こうして学習されたアテンションの重みは、入力文の単語と、出力文の単語の関連性を学習していると言うこともできます。\n",
    "\n",
    "![seq2seq with attation model](https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg)\n",
    "\n",
    "from \"アテンションを用いたニューラル機械翻訳 -- tensorflow.org\" https://www.tensorflow.org/tutorials/text/nmt_with_attention  \n",
    "original \"Effective Approaches to Attention-based Neural Machine Translation, Minh-Thang Luong et al.\" https://arxiv.org/abs/1508.04025v5\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
    "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル構築に必要なパラメータ定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 21908,
     "status": "ok",
     "timestamp": 1612533623222,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "ZDYSOGLzYbP8"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(train_input)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(train_input) // BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練用データセットの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.data.Dataset`では、データのシャッフル`shuffle`やバッチ化`batch`を使ったメソッドチェインでデータの加工が可能です。  \n",
    "サイズの大きなデータセットの場合、`prefetch`や`cache`を行うことで、高速化も期待できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 21908,
     "status": "ok",
     "timestamp": 1612533623222,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "ZDYSOGLzYbP8"
   },
   "outputs": [],
   "source": [
    "dataset = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 入力データのshapeの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27557,
     "status": "ok",
     "timestamp": 1612531066914,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "OkZvi19gYp03",
    "outputId": "f0d807c6-9df8-44e2-9752-8d56e48e416f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 18]), TensorShape([64, 18]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoderの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、`Embedding`レイヤと`GRU`レイヤを1つずつ使ったシンプルなエンコーダを定義します。  \n",
    "`tf.keras`を使ったモデル定義の方法としては、`tf.keras.Sequential`を使う方法や、レイヤの数珠つなぎを自分で作成するFunctional APIがありますが、ここでは`tf.keras.Model`を継承したサブクラス化の手法を使用しています。\n",
    "サブクラスでのモデル定義では、レイヤなどの定義を初期化メソッド（ __init__ ）でインスタンス変数を使って行い、クラスを関数として呼び出すためのcallメソッドで、順方向のデータ処理の流れを定義します。\n",
    "\n",
    "\n",
    "リカレントニューラルネットワークでよく使われるのは`LSTM`ですが、ここではこれを簡略化した`GRU`を使うことで、訓練に要する時間を節約します。\n",
    "\n",
    "単純なSeq2Seqモデルとは異なり、GRUからはシーケンスと状態を出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 21881,
     "status": "ok",
     "timestamp": 1612533623226,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "YYHYgc4hYwly"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoderの出力shapeの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23528,
     "status": "ok",
     "timestamp": 1612533624879,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "v5fs_ECmZP8N",
    "outputId": "b516d329-0f71-4394-b486-d79e4a389450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 18, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# サンプル入力\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BahdanauAttentionの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代表的なAttentionの定義には、上記のようにLuongの論文で発表された内積型アテンションと、[Neural Machine Translation by Jointly Learning to Align and Translate Dzmitry Bahdanau et al.](https://arxiv.org/abs/1409.0473)で提案された加法アテンションがありますが、ここではBahdanau Attentionと呼ばれる後者の加法アテンションをtf.kerasのレイヤとして実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 23503,
     "status": "ok",
     "timestamp": 1612533624880,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "fRy4fGRXZU9P"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # スコアを計算するためにこのように加算を実行する\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # スコアを self.V に適用するために最後の軸は 1 となる\n",
    "        # self.V に適用する前のテンソルの shape は  (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "                      self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights の shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector の合計後の shape == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BahdanauAttentionの出力shapeの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23787,
     "status": "ok",
     "timestamp": 1612533625170,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "QaX0KziyZoN5",
    "outputId": "bbb96965-3606-43a7-ee8a-11950147e010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 18, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_layer = BahdanauAttention(10)\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoderの定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoderでは、Attentionをレイヤとして組み込み、Encoderの状態と出力を与えて、コンテキストベクトルとアテンションの重みを計算します。 　\n",
    "また、Decorderの入力に、コンテキストベクトルを結合したものをGRUに渡し、その出力を全結合層に渡して次の単語を予測します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 23763,
     "status": "ok",
     "timestamp": 1612533625171,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "yzuNjW0lZs1y"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # アテンションのため\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output の shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # 埋め込み層を通過したあとの x の shape  == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # 結合後の x の shape == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # 結合したベクトルを GRU 層に渡す\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoderの出力shapeの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23758,
     "status": "ok",
     "timestamp": 1612533625171,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "yP8fSgqDZ9Ci",
    "outputId": "28bed07a-7565-40d5-a52f-f6dc025ebf43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 6952)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 損失関数の定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoderの出力は多クラス分類であるため、損失関数には`tf.keras.losses.SparseCategoricalCrossentropy`を使います。この例ではDecoder内部でsoftmax変換をかけていないので、`from_logit=True`に設定しています。また、バッチごとの損失をそのまま受け取りたいので、`reduction='none'`に設定します。\n",
    "\n",
    "\n",
    "パディングされたデータで正しく損失値を計算するために、パディングからmaskを計算して計算から除外しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 23733,
     "status": "ok",
     "timestamp": 1612533625172,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "xOmW4oGQaBuJ"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                             from_logits=True, reduction='none')\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### チェックポイントの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 23729,
     "status": "ok",
     "timestamp": 1612533625173,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "j1xOnT6oaOCY"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練の実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 訓練の1ステップを定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力データのバッチ1つずつに対応する`train_step()`関数を定義します。  \n",
    "勾配計算を行うために、`with tf.GradientTape() as tape`のコンテキストでバッチの順方向処理を行います。  \n",
    "訓練の効率を上げるために、前ステップでDecoderが予測したトークンではなく、教師データ（target）の該当位置のトークンを使用しています。これをTeacher Forcingと呼びます。  \n",
    "順方向処理が終わったら、`tape`を使って損失の訓練可能パラメータに対する勾配を計算し、計算された勾配をオプティマイザに渡してパラメータを更新します。\n",
    "\n",
    "この関数は`@tf.function`でアノテートし、TensorFlowの計算グラフ中で計算できるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 23725,
     "status": "ok",
     "timestamp": 1612533625174,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "DaknH7tgaTEt"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([ja_vocab.index('<start>')] * BATCH_SIZE, 1)\n",
    "\n",
    "        # Teacher Forcing - 正解値を次の入力として供給\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # Teacher Forcing を使用\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練ループ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練用データを1バッチずつ取り出し、上で定義した`train_step()`関数を使ってバッチごとの損失からエポックごとの損失を計算して経過時間とともに表示します。  \n",
    "この例では、100バッチごとに損失を表示し、また、2エポックごとにチェックポイントの保存を行なっています。  \n",
    "validationデータを使用する場合には、エポックごと、あるいは定義したエポック感覚でvalidation lossを計算することもできます。その際には、勾配計算とパラメータ更新は行なってはいけません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1986767,
     "status": "ok",
     "timestamp": 1612535588222,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "5bNwa8eCa0Ru",
    "outputId": "d3629362-c291-47dc-8ec8-c49648190c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 6.1205\n",
      "Epoch 1 Batch 100 Loss 2.6564\n",
      "Epoch 1 Batch 200 Loss 2.3286\n",
      "Epoch 1 Batch 300 Loss 2.2678\n",
      "Epoch 1 Batch 400 Loss 2.2476\n",
      "Epoch 1 Loss 2.5152\n",
      "Time taken for 1 epoch 54.825743436813354 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.8989\n",
      "Epoch 2 Batch 100 Loss 1.9250\n",
      "Epoch 2 Batch 200 Loss 1.8727\n",
      "Epoch 2 Batch 300 Loss 1.8464\n",
      "Epoch 2 Batch 400 Loss 1.8113\n",
      "Epoch 2 Loss 1.8795\n",
      "Time taken for 1 epoch 36.00258159637451 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.5908\n",
      "Epoch 3 Batch 100 Loss 1.7378\n",
      "Epoch 3 Batch 200 Loss 1.7886\n",
      "Epoch 3 Batch 300 Loss 1.6569\n",
      "Epoch 3 Batch 400 Loss 1.5471\n",
      "Epoch 3 Loss 1.6218\n",
      "Time taken for 1 epoch 35.02392625808716 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.3151\n",
      "Epoch 4 Batch 100 Loss 1.3490\n",
      "Epoch 4 Batch 200 Loss 1.3743\n",
      "Epoch 4 Batch 300 Loss 1.2452\n",
      "Epoch 4 Batch 400 Loss 1.2473\n",
      "Epoch 4 Loss 1.3584\n",
      "Time taken for 1 epoch 35.90100336074829 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.0758\n",
      "Epoch 5 Batch 100 Loss 1.1607\n",
      "Epoch 5 Batch 200 Loss 1.1555\n",
      "Epoch 5 Batch 300 Loss 0.9708\n",
      "Epoch 5 Batch 400 Loss 1.0142\n",
      "Epoch 5 Loss 1.1083\n",
      "Time taken for 1 epoch 35.436342000961304 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.9121\n",
      "Epoch 6 Batch 100 Loss 0.8116\n",
      "Epoch 6 Batch 200 Loss 0.8035\n",
      "Epoch 6 Batch 300 Loss 0.8982\n",
      "Epoch 6 Batch 400 Loss 0.8625\n",
      "Epoch 6 Loss 0.8936\n",
      "Time taken for 1 epoch 35.70264744758606 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.6702\n",
      "Epoch 7 Batch 100 Loss 0.6721\n",
      "Epoch 7 Batch 200 Loss 0.9026\n",
      "Epoch 7 Batch 300 Loss 0.7088\n",
      "Epoch 7 Batch 400 Loss 0.7558\n",
      "Epoch 7 Loss 0.7126\n",
      "Time taken for 1 epoch 35.216952323913574 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.5980\n",
      "Epoch 8 Batch 100 Loss 0.5206\n",
      "Epoch 8 Batch 200 Loss 0.5894\n",
      "Epoch 8 Batch 300 Loss 0.6228\n",
      "Epoch 8 Batch 400 Loss 0.6692\n",
      "Epoch 8 Loss 0.5618\n",
      "Time taken for 1 epoch 35.708061933517456 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.4565\n",
      "Epoch 9 Batch 100 Loss 0.4294\n",
      "Epoch 9 Batch 200 Loss 0.4012\n",
      "Epoch 9 Batch 300 Loss 0.4475\n",
      "Epoch 9 Batch 400 Loss 0.4109\n",
      "Epoch 9 Loss 0.4322\n",
      "Time taken for 1 epoch 35.18329071998596 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.2578\n",
      "Epoch 10 Batch 100 Loss 0.2605\n",
      "Epoch 10 Batch 200 Loss 0.3044\n",
      "Epoch 10 Batch 300 Loss 0.4032\n",
      "Epoch 10 Batch 400 Loss 0.3971\n",
      "Epoch 10 Loss 0.3284\n",
      "Time taken for 1 epoch 36.05557656288147 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.2177\n",
      "Epoch 11 Batch 100 Loss 0.2417\n",
      "Epoch 11 Batch 200 Loss 0.2564\n",
      "Epoch 11 Batch 300 Loss 0.2441\n",
      "Epoch 11 Batch 400 Loss 0.2497\n",
      "Epoch 11 Loss 0.2475\n",
      "Time taken for 1 epoch 35.37613773345947 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.1719\n",
      "Epoch 12 Batch 100 Loss 0.1500\n",
      "Epoch 12 Batch 200 Loss 0.2019\n",
      "Epoch 12 Batch 300 Loss 0.1917\n",
      "Epoch 12 Batch 400 Loss 0.1744\n",
      "Epoch 12 Loss 0.1863\n",
      "Time taken for 1 epoch 35.796715259552 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.1014\n",
      "Epoch 13 Batch 100 Loss 0.1369\n",
      "Epoch 13 Batch 200 Loss 0.1263\n",
      "Epoch 13 Batch 300 Loss 0.1344\n",
      "Epoch 13 Batch 400 Loss 0.1655\n",
      "Epoch 13 Loss 0.1427\n",
      "Time taken for 1 epoch 35.068371295928955 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0863\n",
      "Epoch 14 Batch 100 Loss 0.0797\n",
      "Epoch 14 Batch 200 Loss 0.1316\n",
      "Epoch 14 Batch 300 Loss 0.1285\n",
      "Epoch 14 Batch 400 Loss 0.1099\n",
      "Epoch 14 Loss 0.1177\n",
      "Time taken for 1 epoch 36.032644271850586 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0955\n",
      "Epoch 15 Batch 100 Loss 0.0894\n",
      "Epoch 15 Batch 200 Loss 0.0855\n",
      "Epoch 15 Batch 300 Loss 0.0912\n",
      "Epoch 15 Batch 400 Loss 0.1218\n",
      "Epoch 15 Loss 0.0979\n",
      "Time taken for 1 epoch 35.50360679626465 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0802\n",
      "Epoch 16 Batch 100 Loss 0.0885\n",
      "Epoch 16 Batch 200 Loss 0.0914\n",
      "Epoch 16 Batch 300 Loss 0.1033\n",
      "Epoch 16 Batch 400 Loss 0.1205\n",
      "Epoch 16 Loss 0.0874\n",
      "Time taken for 1 epoch 35.70587229728699 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0667\n",
      "Epoch 17 Batch 100 Loss 0.0704\n",
      "Epoch 17 Batch 200 Loss 0.0645\n",
      "Epoch 17 Batch 300 Loss 0.0903\n",
      "Epoch 17 Batch 400 Loss 0.1025\n",
      "Epoch 17 Loss 0.0813\n",
      "Time taken for 1 epoch 35.213725566864014 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0798\n",
      "Epoch 18 Batch 100 Loss 0.0582\n",
      "Epoch 18 Batch 200 Loss 0.0616\n",
      "Epoch 18 Batch 300 Loss 0.0803\n",
      "Epoch 18 Batch 400 Loss 0.1104\n",
      "Epoch 18 Loss 0.0778\n",
      "Time taken for 1 epoch 35.72765564918518 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0653\n",
      "Epoch 19 Batch 100 Loss 0.0916\n",
      "Epoch 19 Batch 200 Loss 0.0706\n",
      "Epoch 19 Batch 300 Loss 0.0814\n",
      "Epoch 19 Batch 400 Loss 0.0770\n",
      "Epoch 19 Loss 0.0756\n",
      "Time taken for 1 epoch 35.15982532501221 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0629\n",
      "Epoch 20 Batch 100 Loss 0.0837\n",
      "Epoch 20 Batch 200 Loss 0.0646\n",
      "Epoch 20 Batch 300 Loss 0.0686\n",
      "Epoch 20 Batch 400 Loss 0.0737\n",
      "Epoch 20 Loss 0.0754\n",
      "Time taken for 1 epoch 35.86249828338623 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "              print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                     batch,\n",
    "                                                     batch_loss.numpy()))\n",
    "    # 2 エポックごとにモデル（のチェックポイント）を保存\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練済みモデルの評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練済みのモデルを使って実際に翻訳を実行し、その性能を見てみたいと思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価用関数の定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前処理を行なっていない英文を受け取り、翻訳モデルでの翻訳結果（分かち書き）を返す`evaluate()`関数を定義します。  \n",
    "モデルは、バッチデータを対象としていることに注意が必要です。\n",
    "\n",
    "また、後でAttentionの重みを描画できるように保存しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 1986744,
     "status": "ok",
     "timestamp": 1612535588224,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "H6kO2HY0bEn0"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    sentence = preprocess(sentence)\n",
    "    \n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    inputs = en_vectorizer([sentence])\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([ja_vocab.index('<start>')], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # 後ほどプロットするためにアテンションの重みを保存\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        if ja_vocab[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        result += ja_vocab[predicted_id] + ' '\n",
    "\n",
    "        # 予測された ID がモデルに戻される\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attentionの重みをプロットする関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1986740,
     "status": "ok",
     "timestamp": 1612535588225,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "tnwoWfkYfwBZ"
   },
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "英文の入力を翻訳し、翻訳結果とともに表示する関数です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 1986735,
     "status": "ok",
     "timestamp": 1612535588226,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "q-zIxy2Zf3vw"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後のチェックポイントをencoderとdecorderにロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1986983,
     "status": "ok",
     "timestamp": 1612535588478,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "mIbzsxI-f8Z9",
    "outputId": "59c2afce-8f46-45af-c773-e8be712eb93a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0fe586c550>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_dir の中の最後のチェックポイントを復元\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "executionInfo": {
     "elapsed": 1987264,
     "status": "ok",
     "timestamp": 1612535588788,
     "user": {
      "displayName": "Masatoshi Itagaki",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjjMZX1uH0izIppjc9JsftJYiUHWDycpKYMG80UVQ=s64",
      "userId": "04462290006021813429"
     },
     "user_tz": -540
    },
    "id": "aX4evgWVf9xa",
    "outputId": "831a9943-b7d0-4458-c854-0203c14ea490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> i am a little out of sorts today . <end>\n",
      "Predicted translation: 今日 は 少し 気分 が 悪 い 。 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"i am a little out of sorts today .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テスト用データセットを使った評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "時間節約のため、テスト用データセットの先頭300件を対象として、訓練済みモデルによる翻訳を行い、正解（翻訳例）との比較を行うためのデータフレームを作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "9qYv1rYq1Lu5"
   },
   "outputs": [],
   "source": [
    "input_sentences = load_data(os.path.join(data_dir, 'test.en'))\n",
    "target_sentences = load_data(os.path.join(data_dir, 'test.ja'))\n",
    "\n",
    "input_sentences = input_sentences[:TEST_SIZE_LIMIT]\n",
    "target_sentences = target_sentences[:TEST_SIZE_LIMIT]\n",
    "predicted_sentences = []\n",
    "\n",
    "for input_en in input_sentences:\n",
    "    predicted_ja, _, _ = evaluate(preprocess(input_en))\n",
    "    predicted_sentences.append(''.join(predicted_ja[:-1]))\n",
    "\n",
    "result_df = pd.DataFrame({'input_sentence': input_sentences,\n",
    "                          'target_sentence': target_sentences,\n",
    "                          'predicted_sentence': predicted_sentences})  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BLEUスコアによる評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機械翻訳のように、テキスト生成で正解あるいはお手本となるテキストにどれだけ近い出力ができたかを評価する指標としてBLUEスコアがあります。\n",
    "\n",
    "BLEUスコアの定義は下記の通りで、基本はN-グラム単位での一致がどれくらいあるかです。\n",
    "\n",
    "$$\n",
    "    BLEU = BP_{BLEU} \\times \\exp(\\sum_{i=0}^Nw_n\\log p_n) \\\\\n",
    "    p_n = \\frac{\\sum_i翻訳文iと参照訳iで一致したn–gram数}{\\sum_i翻訳文i中の全n–gram数} \\\\\n",
    "    w_n = \\frac{1}{N} \\\\\n",
    "    BP_{BLEU} = \n",
    "        \\begin{cases}\n",
    "            1 \\quad c \\geqq r \\\\\n",
    "            \\exp(1-\\frac{r}{c}) \\quad c < r \\\\\n",
    "        \\end{cases} \\\\\n",
    "        ただし、\n",
    "        \\begin{cases}\n",
    "        c = \\sum_i 翻訳文の長さ \\\\ \n",
    "        r = \\sum_{参照訳集合} 参照訳中で対応する翻訳文に最も近い長さ \\\\\n",
    "        \\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "ペナルティ $BP_{BLEU}$ は、短い翻訳文の一致度が高くなることに対する対策です。\n",
    "\n",
    "ただし、Nが大きくなると一致度が低下し、スコアが急激に低下する問題があるため、これを平滑化する手法がいくつも提案されています。  \n",
    "\n",
    "今回は、nltkライブラリの`nltk.translate.blue_score.sentence_bleu()`を使用して計算していますが、このライブラリでmethod4として実装されている平滑化手法を使用しています。\n",
    "\n",
    "下記のコードでBLEU値を計算し、データフレームに列を追加しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "16qn07BeMCJs"
   },
   "outputs": [],
   "source": [
    "bleu_scores = []\n",
    "for row in result_df.itertuples():\n",
    "    bleu_scores.append(\n",
    "        sentence_bleu(row.target_sentence, row.predicted_sentence,\n",
    "                      smoothing_function=SmoothingFunction().method4)\n",
    "    )\n",
    "result_df['bleu_score'] = bleu_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "bGnwSEkf9HlM",
    "outputId": "9ed3d5f6-4579-49b9-c4e1-eee0f13b19c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_sentence</th>\n",
       "      <th>target_sentence</th>\n",
       "      <th>predicted_sentence</th>\n",
       "      <th>bleu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>they finally acknowledged it as true .</td>\n",
       "      <td>彼 ら は つい に それ が 真実 だ と 認め た 。</td>\n",
       "      <td>彼 ら は それ を 言 っ た 。</td>\n",
       "      <td>0.269130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>he didn 't care for swimming .</td>\n",
       "      <td>彼 は 水泳 が 得意 で は な かっ た 。</td>\n",
       "      <td>彼 は 泳ぎ を 入れ な かっ た 。</td>\n",
       "      <td>0.243904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>he is no less kind than his sister .</td>\n",
       "      <td>彼 は お 姉 さん に 劣 ら ず 親切 だ 。</td>\n",
       "      <td>彼 は お 姉 さん と 話 す こと は 容易 で は な い 。</td>\n",
       "      <td>0.127277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you must be back before ten .</td>\n",
       "      <td>１０ 時 前 に 戻 ら な けれ ば な ら な い 。</td>\n",
       "      <td>10 時 まで に 戻 る な 。</td>\n",
       "      <td>0.268659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>break a leg .</td>\n",
       "      <td>成功 を 祈 る わ 。</td>\n",
       "      <td>い い な さ い 。</td>\n",
       "      <td>0.356676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>i 'm very sleepy now .</td>\n",
       "      <td>今 とても 眠 い 。</td>\n",
       "      <td>とても 疲れ で す 。</td>\n",
       "      <td>0.399584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>above the music , i could hear her crying .</td>\n",
       "      <td>音楽 が な っ て い る の に 彼女 の 鳴き声 が 聞こえ た 。</td>\n",
       "      <td>その 先生 の 話 を 知 ら せ ん だ と 思 っ た の で い る</td>\n",
       "      <td>0.107584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>we had the meeting in this room last friday .</td>\n",
       "      <td>先週 の 金曜 日 この 部屋 で 会合 が あ っ た 。</td>\n",
       "      <td>この 部屋 の 部屋 が あ り ま し た 。</td>\n",
       "      <td>0.196274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>who do you want to speak to ?</td>\n",
       "      <td>お 話 に な る 方 の お 名前 は 。</td>\n",
       "      <td>誰 が ため に 話 し た い で す か 。</td>\n",
       "      <td>0.160257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>his father eats there twice a week .</td>\n",
       "      <td>彼 の 父 は １ 週間 に ２ 回 そこ で 食べ る 。</td>\n",
       "      <td>彼 の お 父 さん に 戻 っ て い る 。</td>\n",
       "      <td>0.184321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    input_sentence  \\\n",
       "0           they finally acknowledged it as true .   \n",
       "1                   he didn 't care for swimming .   \n",
       "2             he is no less kind than his sister .   \n",
       "3                    you must be back before ten .   \n",
       "4                                    break a leg .   \n",
       "..                                             ...   \n",
       "295                         i 'm very sleepy now .   \n",
       "296    above the music , i could hear her crying .   \n",
       "297  we had the meeting in this room last friday .   \n",
       "298                  who do you want to speak to ?   \n",
       "299           his father eats there twice a week .   \n",
       "\n",
       "                           target_sentence  \\\n",
       "0            彼 ら は つい に それ が 真実 だ と 認め た 。   \n",
       "1                 彼 は 水泳 が 得意 で は な かっ た 。   \n",
       "2                彼 は お 姉 さん に 劣 ら ず 親切 だ 。   \n",
       "3            １０ 時 前 に 戻 ら な けれ ば な ら な い 。   \n",
       "4                             成功 を 祈 る わ 。   \n",
       "..                                     ...   \n",
       "295                            今 とても 眠 い 。   \n",
       "296  音楽 が な っ て い る の に 彼女 の 鳴き声 が 聞こえ た 。   \n",
       "297         先週 の 金曜 日 この 部屋 で 会合 が あ っ た 。   \n",
       "298                 お 話 に な る 方 の お 名前 は 。   \n",
       "299         彼 の 父 は １ 週間 に ２ 回 そこ で 食べ る 。   \n",
       "\n",
       "                        predicted_sentence  bleu_score  \n",
       "0                       彼 ら は それ を 言 っ た 。    0.269130  \n",
       "1                     彼 は 泳ぎ を 入れ な かっ た 。    0.243904  \n",
       "2       彼 は お 姉 さん と 話 す こと は 容易 で は な い 。    0.127277  \n",
       "3                        10 時 まで に 戻 る な 。    0.268659  \n",
       "4                              い い な さ い 。    0.356676  \n",
       "..                                     ...         ...  \n",
       "295                           とても 疲れ で す 。    0.399584  \n",
       "296  その 先生 の 話 を 知 ら せ ん だ と 思 っ た の で い る    0.107584  \n",
       "297               この 部屋 の 部屋 が あ り ま し た 。    0.196274  \n",
       "298               誰 が ため に 話 し た い で す か 。    0.160257  \n",
       "299               彼 の お 父 さん に 戻 っ て い る 。    0.184321  \n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9hQ_XKxIQ2W",
    "outputId": "3e30de47-f27d-48d9-9cb2-ddb562fbeb71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1926190246410859"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.bleu_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMgTzeT+AoMej2E7PB7H2z+",
   "collapsed_sections": [],
   "name": "seq2seq_with_attention.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
